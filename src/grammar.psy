grammar_install ::= func(-> v0)
{
	grammar_setup_unops();
	grammar_setup_biops();
	grammar_setup_base_operators();

	grammar_exprify();
	grammar_parentheses();
	foreach_expr(grammar_parentheses_expr);

	grammar_deref();
	foreach_expr(grammar_deref_expr);

	grammar_typename();
	foreach_expr(grammar_typename_array_length_expr);
	//grammar_typename_array_length_expr(ast_expr_tag.literal);
	grammar_decl_explicitly_typed();
	grammar_decl_deducibly_typed();

	foreach_expr(grammar_decl_init_expr);

	grammar_struct();
	grammar_function();

	foreach_expr(grammar_stmtify_expr);
	grammar_stmtify_nonexpr();

	foreach_stmt(grammar_commit_stmt);
};

is_already_an_operator ::= func(tok : lex_token -> bool)
{
	i : u64 mut;
	for(i = 0, i < ast_all_op_tokens_cursor, i = i + 1)
	{
		if(deref(ast_all_op_tokens # i) == tok)
		{
			return true;
		}
	}
	return false;
};

grammar_setup_unops ::= func(-> v0)
{
	deref(ast_unop_tokens # (ast_unop.minus@s64)) = (lex_token.dash);
	deref(ast_unop_tokens # (ast_unop.bitwise_invert@s64)) = (lex_token.bitwise_invert);
	deref(ast_unop_tokens # (ast_unop.logical_invert@s64)) = (lex_token.logical_invert);
	deref(ast_unop_tokens # (ast_unop.reference@s64)) = (lex_token.keyword_ref);

	i : u64 mut;
	for(i = 0, i < __countof(ast_unop), i = i + 1)
	{
		tok ::= deref(ast_unop_tokens # (i + 1));
		if(!is_already_an_operator(tok))
		{
			deref(ast_all_op_tokens # ast_all_op_tokens_cursor) = tok;
			ast_all_op_tokens_cursor = (ast_all_op_tokens_cursor + 1);
		}
	}
};

grammar_setup_biops ::= func(-> v0)
{
	deref(ast_biop_tokens # (ast_biop.assign@s64)) = (lex_token.assign);
	deref(ast_biop_tokens # (ast_biop.compare_equal@s64)) = (lex_token.compare);
	deref(ast_biop_tokens # (ast_biop.compare_not_equal@s64)) = (lex_token.comparen);
	deref(ast_biop_tokens # (ast_biop.compare_less@s64)) = (lex_token.oanglebrack);
	deref(ast_biop_tokens # (ast_biop.compare_less_equal@s64)) = (lex_token.loreq);
	deref(ast_biop_tokens # (ast_biop.compare_greater@s64)) = (lex_token.canglebrack);
	deref(ast_biop_tokens # (ast_biop.compare_greater_equal@s64)) = (lex_token.goreq);
	deref(ast_biop_tokens # (ast_biop.add@s64)) = (lex_token.plus);
	deref(ast_biop_tokens # (ast_biop.sub@s64)) = (lex_token.dash);
	deref(ast_biop_tokens # (ast_biop.mul@s64)) = (lex_token.asterisk);
	deref(ast_biop_tokens # (ast_biop.div@s64)) = (lex_token.fslash);
	deref(ast_biop_tokens # (ast_biop.bitwise_or@s64)) = (lex_token.bitwise_or);
	deref(ast_biop_tokens # (ast_biop.bitwise_and@s64)) = (lex_token.bitwise_and);
	deref(ast_biop_tokens # (ast_biop.logical_or@s64)) = (lex_token.logical_or);
	deref(ast_biop_tokens # (ast_biop.logical_and@s64)) = (lex_token.logical_and);
	deref(ast_biop_tokens # (ast_biop.xor@s64)) = (lex_token.bitwise_exor);
	deref(ast_biop_tokens # (ast_biop.bitshift_left@s64)) = (lex_token.oanglebrack2);
	deref(ast_biop_tokens # (ast_biop.bitshift_right@s64)) = (lex_token.canglebrack2);
	deref(ast_biop_tokens # (ast_biop.modulo@s64)) = (lex_token.modulo);
	deref(ast_biop_tokens # (ast_biop.at@s64)) = (lex_token.keyword_at);
	deref(ast_biop_tokens # (ast_biop.field@s64)) = (lex_token.dot);
	deref(ast_biop_tokens # (ast_biop.ptr_field@s64)) = (lex_token.arrow);
	deref(ast_biop_tokens # (ast_biop.cast@s64)) = (lex_token.cast);

	i : u64 mut;
	for(i = 0, i < __countof(ast_biop), i = i + 1)
	{
		tok ::= deref(ast_biop_tokens # (i + 1));
		if(!is_already_an_operator(tok))
		{
			deref(ast_all_op_tokens # ast_all_op_tokens_cursor) = tok;
			ast_all_op_tokens_cursor = (ast_all_op_tokens_cursor + 1);
		}
	}
};

grammar_setup_base_operators ::= func(-> v0)
{
	// so all tokens that can be either an unop and/or a biop will get these reduction rules
	// all of these will get both reductions for unop/biop and it is the responsibility of the grammar_rule to check if you've misused any of them.
	i : u64 mut;
	for(i = 0, i < ast_all_op_tokens_cursor, i = i + 1)
	{
		tok ::= deref(ast_all_op_tokens # i);
		grammar_setup_base_operator(tok);
		grammar_setup_base_operator_expr(tok);
	}
};

grammar_setup_base_operator ::= func(tok : lex_token -> v0)
{
	// lets say we have
	// 5 + 5
	// first we see a literal expr with a lookahead(+)
	// we stash the literal expr so its only +
		// with lookahead(token)
		// due to the biop rule that gets stashed too
	// so now the rhs comes and gets exprified
	// stash is: literal-expr, token (front)
	// unstash token and match to unop
		//: token literal-expr
	// now match the unop-expr with stash(literal-expr)
	// to turn it into a biop


	// any biop or unop operator symbol gets stashed if:
	// unop: its the token itself
	grammar_hashtable_insert(state1(
		token(tok),
	zero, zero),
	grammar_rule{.fn := rule_stash;});
};

grammar_setup_base_operator_expr ::= func(tok : lex_token -> v0)
{
	i : u64 mut;
	// ok so this is highly gnarly
	// we want to iterate over every single expr tag for both exprtag1 and exprtag2
	// some grammar rules include both of them in the node state which will require a quadratic iteration
	// but we cant do this for rules which include only 1 (coz it will be done multiple times and panic coz inserting the same grammar_hashtable entry

	// lets do all the exprtag1 only stuff (lhs only)
	
	exprtag1 : ast_expr_tag mut;
	exprtag2 : ast_expr_tag mut;
	for(i = 0, i < __countof(ast_expr_tag), i = i + 1)
	{
		exprtag1 = ((i + 1)@ast_expr_tag);
		grammar_hashtable_insert(state1(
			expr(exprtag1),
		token(tok), zero),
		grammar_rule{.fn := rule_stash;});
	}

	// now exprtag2 only stuff (rhs only)
	for(i = 0, i < __countof(ast_expr_tag), i = i + 1)
	{
		exprtag2 = ((i + 1)@ast_expr_tag);
		// ok this is at least an unop on the way (potentially a biop if another expr is stashtop after this unstash)
		grammar_hashtable_insert(state1(
			expr(exprtag2),
		zero, token(tok)),
		grammar_rule{.fn := rule_unstash;});

		// if there's not another expr stashed then this is an unop
		grammar_hashtable_insert(state2(
			token(tok),
			expr(exprtag2),
		zero, zero),
		grammar_rule{.fn := rule_token_x_expr_x2unop;});
	}

	j : u64 mut;
	// and finally both
	for(i = 0, i < __countof(ast_expr_tag), i = i + 1)
	{
		exprtag1 = ((i + 1)@ast_expr_tag);
		for(j = 0, j < __countof(ast_expr_tag), j = j + 1)
		{
			exprtag2 = ((j + 1)@ast_expr_tag);

			// but if there is then this is gonna be a biop (unstash first)
			grammar_hashtable_insert(state2(
				token(tok),
				expr(exprtag2),
			zero, expr(exprtag1)),
			grammar_rule{.fn := rule_unstash;});

			grammar_hashtable_insert(state3(
				expr(exprtag1),
				token(tok),
				expr(exprtag2),
			zero, zero),
			grammar_rule{.fn := rule_expr_x_token_x_expr_y2biop;});
		}
	}
};

grammar_exprify ::= func(-> v0)
{
	// symbol expression
	grammar_hashtable_insert(state1(
		token(lex_token.symbol),
	zero, zero),
	grammar_rule{.fn := rule_token_symbol2symbol_expr;});

	// literal expression (numeric)
	grammar_hashtable_insert(state1(
		token(lex_token.numeric_literal),
	zero, zero),
	grammar_rule{.fn := rule_token_numeric_literal2literal_expr;});

	// literal expression (char)
	grammar_hashtable_insert(state1(
		token(lex_token.char_literal),
	zero, zero),
	grammar_rule{.fn := rule_token_char_literal2literal_expr;});

	// literal expression (string)
	grammar_hashtable_insert(state1(
		token(lex_token.string_literal),
	zero, zero),
	grammar_rule{.fn := rule_token_string_literal2literal_expr;});

	// literal expression (bool): 'true' and 'false'
	grammar_hashtable_insert(state1(
		token(lex_token.keyword_true),
	zero, zero),
	grammar_rule{.fn := rule_token_keyword_true2literal_expr;});
	grammar_hashtable_insert(state1(
		token(lex_token.keyword_false),
	zero, zero),
	grammar_rule{.fn := rule_token_keyword_false2literal_expr;});

	/// zero expression
	grammar_hashtable_insert(state1(
		token(lex_token.keyword_zero),
	zero, zero),
	grammar_rule{.fn := rule_token_keyword_zero2literal_expr;});
};

grammar_parentheses ::= func(-> v0)
{
	grammar_hashtable_insert(state1(
		token(lex_token.oparen),
	zero, zero),
	grammar_rule{.fn := rule_stash;});
};

grammar_parentheses_expr ::= func(exprtag : ast_expr_tag -> v0)
{
	grammar_hashtable_insert(state1(
		expr(exprtag),
	token(lex_token.cparen), token(lex_token.oparen))
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		expr(exprtag),
		token(lex_token.cparen),
	zero, token(lex_token.oparen))
	grammar_rule{.fn := rule_unstash;});
		
	grammar_hashtable_insert(state3(
		token(lex_token.oparen),
		expr(exprtag),
		token(lex_token.cparen),
	zero, zero),
	grammar_rule{.fn := rule_token_oparen_expr_x_token_cparen2expr;});
};

grammar_deref ::= func(-> v0)
{
	grammar_hashtable_insert(state1(
		token(lex_token.obrack),
	zero, zero),
	grammar_rule{.fn := rule_stash;});
};

grammar_deref_expr ::= func(exprtag : ast_expr_tag -> v0)
{
	// try not to early munch exprs here. make sure the lookahead is cbrack
	// btw yes we do stash obrack and treat that as our equivalent of an ast_deref_tag
	// most of the time we cant do this because certain things require more than 1 token but deref is just [ expr ]
	// we have a limited number of possible ast states so this allows us to save one.
	// in short: do this sparingly, for anything of nontrivial complexity use a specific ast tag but for something like this its chill + simpler + faster
	grammar_hashtable_insert(state1(
		expr(exprtag),
	token(lex_token.cbrack), token(lex_token.obrack)),
	grammar_rule{.fn := rule_unstash;});
		
	grammar_hashtable_insert(state2(
		token(lex_token.obrack),
		expr(exprtag),
	token(lex_token.cbrack), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state3(
		token(lex_token.obrack),
		expr(exprtag),
		token(lex_token.cbrack),
	zero, zero),
	grammar_rule{.fn := rule_token_obrack_expr_token_cbrack2deref;});
};


grammar_typename ::= func(-> v0)
{
	// under some circumstances we want to treat a symbol as the start of a typename
	// (normally if some certain node is stashtop)
	// we list them all here:

	// normally a symbol by itself (e.g 'foo' is a symbol expression)
	// in the case that we have an await_typename stashed however we can say its a typename
	grammar_hashtable_insert(state1(
		token(lex_token.symbol),
	zero, decl(ast_decl_tag.await_type)),
	grammar_rule{.fn := rule_token_symbol2typename_wip;});

	grammar_hashtable_insert(state1(
		token(lex_token.symbol),
	zero, typename(ast_typename_tag.function_await_return_type)),
	grammar_rule{.fn := rule_token_symbol2typename_wip;});

	// now a wip typename basically stays wip until it doesnt have any lookaheads we expect (in which case we finalise it)
	// but lets do the lookahead first to keep things intuitive.
	// if we see something we like we shift1 to get it into the node array and then process it in some way

	// first are all the typequal tokens.
	// tyqual.mut:
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.wip),
	token(lex_token.qual_mut), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.wip),
		token(lex_token.qual_mut),
	zero, zero),
	grammar_rule{.fn := rule_typename_wip2mut;});

	// tyqual.static:
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.wip),
	token(lex_token.qual_static), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.wip),
		token(lex_token.qual_static),
	zero, zero),
	grammar_rule{.fn := rule_typename_wip2static;});

	// tyqual.weak:
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.wip),
	token(lex_token.qual_weak), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.wip),
		token(lex_token.qual_weak),
	zero, zero),
	grammar_rule{.fn := rule_typename_wip2weak;});

	// ok now pointerness
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.wip),
	token(lex_token.qmark), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.wip),
		token(lex_token.qmark),
	zero, zero),
	grammar_rule{.fn := rule_typename_wip2ptr;});

	// arrayness is somewhat more complicated
	// in theory it would be quite nice to not only allow numeric literals but any expression
	// so we need to put it into an array state and then stash until an expression comes around.
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.wip),
	token(lex_token.obrack), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.wip),
		token(lex_token.obrack),
	zero, zero),
	grammar_rule{.fn := rule_typename_wip2array_await_length;});

	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.array_await_length),
	zero, zero),
	grammar_rule{.fn := rule_stash;});
	// the idea here is that when we see a valid array initialiser we unstash and combine it back into the typename_wip
	// however we want to be explicit in which expr types are valid initialisers
	// so the rest of this logic is in grammar_typename_array_length_expr

	grammar_hashtable_insert(state1(
		token(lex_token.keyword_func),
	token(lex_token.oparen), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		token(lex_token.keyword_func),
		token(lex_token.oparen),
	zero, zero),
	grammar_rule{.fn := rule_keyword_func_keyword_oparen2function_await_param_or_arrow;});

	// no arrow in lookahead, so we will stash until we see a decl
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.function_await_param_or_arrow),
	zero, zero),
	grammar_rule{.fn := rule_stash;});

	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.finalised),
	zero, typename(ast_typename_tag.function_await_param_or_arrow)),
	grammar_rule{.fn := rule_unstash;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.function_await_param_or_arrow),
		decl(ast_decl_tag.finalised),
	token(lex_token.arrow), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state3(
		typename(ast_typename_tag.function_await_param_or_arrow),
		decl(ast_decl_tag.finalised),
		token(lex_token.arrow),
	zero, zero),
	grammar_rule{.fn := rule_typename_function_await_param_or_arrow_decl_finalised_token_arrow2function_await_return_type;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.function_await_param_or_arrow),
		decl(ast_decl_tag.finalised),
	token(lex_token.comma), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state3(
		typename(ast_typename_tag.function_await_param_or_arrow),
		decl(ast_decl_tag.finalised),
		token(lex_token.comma),
	zero, zero),
	grammar_rule{.fn := rule_typename_function_await_param_or_arrow_decl_finalised_token_comma2function_await_param_or_arrow;});

	grammar_hashtable_insert(state3(
		typename(ast_typename_tag.function_await_param_or_arrow),
		decl(ast_decl_tag.finalised),
		token(lex_token.comma),
	token(lex_token.arrow), zero),
	grammar_rule{.fn := rule_error_typename_function_comma_followed_by_arrow;});

	// ok arrow in lookahead 
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.function_await_param_or_arrow),
	token(lex_token.arrow), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.function_await_param_or_arrow),
		token(lex_token.arrow),
	zero, zero),
	grammar_rule{.fn := rule_typename_function_await_param_or_arrow_token_arrow2await_return_type;});

	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.function_await_return_type),
	zero, zero),
	grammar_rule{.fn := rule_stash;});

	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.finalised),
	zero, typename(ast_typename_tag.function_await_return_type)),
	grammar_rule{.fn := rule_unstash;});

	grammar_hashtable_insert(state2(
		typename(ast_typename_tag.function_await_return_type),
		typename(ast_typename_tag.finalised),
	token(lex_token.cparen), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state3(
		typename(ast_typename_tag.function_await_return_type),
		typename(ast_typename_tag.finalised),
		token(lex_token.cparen),
	zero, zero),
	grammar_rule{.fn := rule_typename_function_await_return_type_typename_token_cparen2wip;});

	// maybe todo: decltype

	// ok now that we've done the lookahead possibilities.
	// if we dont see any of those then we assume the lookahead is irrelevant and our typename is now complete.
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.wip),
	zero, zero),
	grammar_rule{.fn := rule_typename_wip2finalised;});
};

grammar_typename_array_length_expr ::= func(exprtag : ast_expr_tag -> v0)
{
	// we need to be quite careful here
	// we dont want to munch before a biop for example
	// so when we see the expr we actually shift again
	// only when its array_await_length,  exprtag, ] do we know for sure
	grammar_hashtable_insert(state1(
		expr(exprtag),
	token(lex_token.cbrack), typename(ast_typename_tag.array_await_length)),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		expr(exprtag),
		token(lex_token.cbrack),
	zero, typename(ast_typename_tag.array_await_length)),
	grammar_rule{.fn := rule_unstash;});

	grammar_hashtable_insert(state3(
		typename(ast_typename_tag.array_await_length),
		expr(exprtag),
		token(lex_token.cbrack),
	zero, zero),
	grammar_rule{.fn := rule_typename_array_await_length_expr_token_semicol2wip;});
	
};

grammar_decl_explicitly_typed ::= func(-> v0)
{
	grammar_hashtable_insert(state1(
		token(lex_token.symbol),
	token(lex_token.colon), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		token(lex_token.symbol),
		token(lex_token.colon),
	zero, zero),
	grammar_rule{.fn := rule_token_symbol_token_colon2decl_awaittype;});

	// a decl.await_type will be stashed until a typename is found
	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.await_type),
	zero, zero),
	grammar_rule{.fn := rule_stash;});

	// unstash await_type if we have a finished typename ready to go.
	grammar_hashtable_insert(state1(
		typename(ast_typename_tag.finalised),
	zero, decl(ast_decl_tag.await_type)),
	grammar_rule{.fn := rule_unstash;});

	// ok if we have a await_type decl and a typename, then we combine them into a basic decl!
	grammar_hashtable_insert(state2(
		decl(ast_decl_tag.await_type),
		typename(ast_typename_tag.finalised),
	zero, zero),
	grammar_rule{.fn := rule_decl_awaittype_typename_finalised2noinit;});

	// if noinit is followed by an initialiser then great we can turn it into an await_init_expr
	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.noinit),
	token(lex_token.initialiser), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		decl(ast_decl_tag.noinit),
		token(lex_token.initialiser),
	zero, zero),
	grammar_rule{.fn := rule_decl_noinit_token_initialiser2await_init_expr;});

	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.await_init_expr),
	zero, zero),
	grammar_rule{.fn := rule_stash;});

	// note: code to handle init-exprs is below in grammar_decl_init_expr.
	// this is so the expr tags allowed can be parameterised

	// ok so lets move on. what if our noinit is *not* followed by an initialiser
	// well then we finalise it without one i.e this is 'foo : u64'
	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.noinit),
	zero, zero),
	grammar_rule{.fn := rule_decl_noinit2finalised;});

	// note: what we do with a finalised decl depends on quite a few things so we dont handle it here.
	// examples could be:
	// - followed by a semicol -> stmtify
	// - function stashed -> add as param
};

grammar_decl_deducibly_typed ::= func(-> v0)
{
	// im not sure deducibly is a word...
	// i mean 'foo ::= 5' instead of 'foo : s64 := 5'
	grammar_hashtable_insert(state2(
		token(lex_token.symbol),
		token(lex_token.colon),
	token(lex_token.initialiser), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state3(
		token(lex_token.symbol),
		token(lex_token.colon),
		token(lex_token.initialiser),
	zero, zero),
	grammar_rule{.fn := rule_token_symbol_token_colon_token_initialiser2decl_await_init_expr;});
};

grammar_decl_init_expr ::= func(exprtag : ast_expr_tag -> v0)
{
	// we have to be very careful not to munch here.
	// we know for sure what tokens will always follow the end of a decl expr
	decl_enders ::= lex_token[3]{lex_token.semicol; lex_token.comma; lex_token.arrow;};

	i : u64 mut;
	for(i = 0, i < (__sizeof(decl_enders) / __sizeof(deref(decl_enders # 0))), i = i + 1)
	{
		grammar_hashtable_insert(state1(
			expr(exprtag),
		token(deref(decl_enders # i)), decl(ast_decl_tag.await_init_expr)),
		grammar_rule{.fn := rule_unstash;});
	}

	grammar_hashtable_insert(state2(
		decl(ast_decl_tag.await_init_expr),
		expr(exprtag),
	zero, zero),
	grammar_rule{.fn := rule_decl_await_init_expr_init_expr2finalised;});
};

grammar_struct ::= func(-> v0)
{
	grammar_hashtable_insert(state3(
		token(lex_token.symbol),
		token(lex_token.colon),
		token(lex_token.initialiser),
	token(lex_token.keyword_struct), zero),
	grammar_rule{.fn := rule_shift2;});

	grammar_hashtable_insert(state5(
		token(lex_token.symbol),
		token(lex_token.colon),
		token(lex_token.initialiser),
		token(lex_token.keyword_struct),
		token(lex_token.obrace),
	zero, zero),
	grammar_rule{.fn := rule_token_symbol_token_colon_token_initialiser_token_keyword_struct_token_obrace2structure_wip;});

	grammar_hashtable_insert(state1(
		structure(ast_structure_tag.wip),
	zero, zero),
	grammar_rule{.fn := rule_stash;});

	// remember, when decls are stmtified they get committed so if we're stashed we get it as a child automatically
	// so lets unstash and finalise ourselves when we see a cbrace

	grammar_hashtable_insert(state1(
		token(lex_token.cbrace),
	zero, structure(ast_structure_tag.wip)),
	grammar_rule{.fn := rule_unstash;});

	grammar_hashtable_insert(state2(
		structure(ast_structure_tag.wip),
		token(lex_token.cbrace),
	zero, zero),
	grammar_rule{.fn := rule_structure_wip_token_cbrace2finalised;});
};

grammar_function ::= func(-> v0)
{
	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.finalised),
	token(lex_token.obrace), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		decl(ast_decl_tag.finalised),
		token(lex_token.obrace),
	zero, zero),
	grammar_rule{.fn := rule_decl_finalised_token_obrace2function_impl;});

	grammar_hashtable_insert(state1(
		function(ast_function_tag.impl),
	zero, zero),
	grammar_rule{.fn := rule_stash;});

	grammar_hashtable_insert(state1(
		token(lex_token.cbrace),
	zero, function(ast_function_tag.impl)),
	grammar_rule{.fn := rule_unstash;});

	grammar_hashtable_insert(state2(
		function(ast_function_tag.impl),
		token(lex_token.cbrace),
	zero, zero),
	grammar_rule{.fn := rule_function_impl_cbrace2finalised;});
};

grammar_stmtify_expr ::= func(exprtag : ast_expr_tag -> v0)
{
	// allow expr(T); to be stmtified
	// non-expr stmtifications belong in grammar_stmtify_nonexpr
	grammar_hashtable_insert(state1(
		expr(exprtag),
	token(lex_token.semicol), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		expr(exprtag),
		token(lex_token.semicol),
	zero, zero),
	grammar_rule{.fn := rule_expr_token_semicol2stmt;});
};

grammar_stmtify_nonexpr ::= func(-> v0)
{
	// any non-exprs that can get stmtified live here.
	// exprs are separate because all expr tags behave the same
	// but each of these are special and require their own rule.
	// decl stmts
	grammar_hashtable_insert(state1(
		decl(ast_decl_tag.finalised),
	token(lex_token.semicol), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		decl(ast_decl_tag.finalised),
		token(lex_token.semicol),
	zero, zero),
	grammar_rule{.fn := rule_decl_finalised_token_semicol2stmt;});

	// structure
	grammar_hashtable_insert(state1(
		structure(ast_structure_tag.finalised),
	token(lex_token.semicol), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		structure(ast_structure_tag.finalised),
		token(lex_token.semicol),
	zero, zero),
	grammar_rule{.fn := rule_structure_finalised_token_semicol2stmt;});

	// function
	grammar_hashtable_insert(state1(
		function(ast_function_tag.finalised),
	token(lex_token.semicol), zero),
	grammar_rule{.fn := rule_shift1;});

	grammar_hashtable_insert(state2(
		function(ast_function_tag.finalised),
		token(lex_token.semicol),
	zero, zero),
	grammar_rule{.fn := rule_function_finalised_token_semicol2stmt;});
};

grammar_commit_stmt ::= func(stmttag : ast_stmt_tag -> v0)
{
	grammar_hashtable_insert(state1(
		stmt(stmttag),
	zero, zero),
	grammar_rule{.fn := rule_commit;});
};
