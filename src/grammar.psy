ar : arena mut& mut;

hashnode ::= func(t : ast_type) -> u64
{
	v ::= (t@s64) * 1093;
	return hash(v);
};

hashtoken ::= func(t : lex_token) -> u64
{
	multiplier ::= (ast_type.unparsed_token)@s64 * 866820901;
	return multiplier ^ hash(t);
};

hashexpr ::= func(t : ast_expr_type) -> u64
{
	multiplier ::= (ast_type.expr)@s64 * 190299117;
	return multiplier ^ hash(t);
};

hashstmt ::= func(t : ast_stmt) -> u64
{
	multiplier ::= (ast_type.stmt)@s64 * 393505272299;
	return multiplier ^ hash(t);
};

hash_state ::= func(nodes : ast&, node_count : u64) -> u64
{
	i : u64 mut;
	hash : u64 mut := zero;
	for(i = 0, i < node_count, i = i + 1)
	{
		curnode ::= deref (nodes at i);
		istoken ::= (curnode.type) == (ast_type.unparsed_token);
		isexpr ::= (curnode.type) == (ast_type.expr);
		isstmt ::= (curnode.type) == (ast_type.stmt);
		if(istoken)
		{
			utok ::= curnode.utok;
			tokdata ::= utok.tok;
			hash = (hash ^ hashtoken(tokdata.tok));
		}
		if(isexpr)
		{
			expr ::= curnode.expr;
			hash = (hash ^ hashexpr(expr.type));
		}
		if(isstmt)
		{
			hash = (hash ^ hashstmt(curnode.stmt));
		}
		if(!istoken)
		{
			if(!isexpr)
			{
				if(!isstmt)
				{
					hash = (hash ^ hashnode(curnode.type));
				}
			}
		}
		hash = hash * 34875947865;
	}
	return hash;
};

parse_action ::= enum
{
	.invalid := 0;
	.reduce := 1;
	.shift := 2;
	.commit := 3;
	.stash := 4;
	.unstash := 5;
	.recurse := 6;
	.error := 7;
};

parse_value ::= struct
{
	action : parse_action;
	offset : u64;
	len : u64;
	errmsg : u8&;
	nodes : ast mut#16;
	nodes_size : u64;
};
grammar_rule ::= struct
{
	fn : func(source : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value;
};

default_rule_errmsg ::= "default rule invoked\n";
default_rule ::= func(source : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.error;
		.errmsg := default_rule_errmsg;
	};
};

[[private]]
parse_table : grammar_rule mut& mut;
[[private]]
parse_table_size : u64 mut;
[[private]]
parse_table_cap : u64 mut;

null_lookahead ::= zero@ast;
null_stash ::= zero@ast;

pty ::= enum
{
	.head := 1;
	.tail := 2;
	.both := 3;
};
grammar_install_impl ::= func(do_work : bool, my_nodes : ast mut&, my_nodes_size : u64, nodes_count : u64, lookahead_node : ast, stash_node : ast, allow_begin_state : bool, rule : grammar_rule) -> v0
{
	if(!do_work)
	{
		return;
	}
	hash : u64 mut := hash_state(my_nodes at 0, nodes_count);
	__memset(my_nodes at 0, 0, my_nodes_size);
	la ::= lookahead_node;
	la_hash : u64 mut := zero;
	if((la.type) != (ast_type.unknown))
	{
		la_hash = (!hash_state(ref la, 1));
		hash = (hash ^ la_hash);
	}
	st ::= stash_node;
	st_hash : u64 mut := zero;
	if((st.type) != (ast_type.unknown))
	{
		st_hash = (!(hash_state(ref st, 1) ^ 101010101));
		hash = (hash ^ st_hash);
	}
	if(allow_begin_state)
	{
		hash = !hash;
	}

	ptr ::= parse_table at (hash % parse_table_cap);
	if(ptr->fn != zero)
	{
		psyc_panic(srcloc_current(), "hash collision detected");
	}
	deref(ptr) = rule;
};

grammar_install ::= macro(nc : u64, la : ast, st : ast, albs : pty, r : grammar_rule) -> v0
{
	grammar_install_impl((albs & (pty.head)) > 0, my_nodes at 0, __sizeof(my_nodes), nc, la, st, true, r);
	grammar_install_impl((albs & (pty.tail)) > 0, my_nodes at 0, __sizeof(my_nodes), nc, la, st, false, r);
};

token ::= macro(t : lex_token) -> ast static
{
	yield ast
	{
		.type := ast_type.unparsed_token;
		.utok := ast_unparsed_token
		{
			.tok := token_data
			{
				.tok := t;
			};
		};
	};
};

node ::= macro(t : ast_type) -> ast static
{
	yield ast
	{
		.type := t;
	};
};

expr ::= macro(t : ast_expr_type) -> ast static
{
	yield ast
	{
		.type := ast_type.expr;
		.expr := ast_expr{.type := t;};
	};
};

stmt ::= macro(t : ast_stmt) -> ast static
{
	yield ast
	{
		.type := ast_type.stmt;
		.stmt := t;
	};
};

rule ::= macro(f : auto) -> grammar_rule
{
	yield grammar_rule{.fn := f;};
};

grammar_get_rule ::= func(hash : u64) -> grammar_rule
{
	idx ::= hash % parse_table_cap;
	// todo: open addressing.
	return deref(parse_table at idx);
};

// REDUCTION SETUP

setup_decls ::= macro() -> v0
{
	firstptr ::= nodes at 0;
	first ::= deref firstptr;
	lastptr ::= nodes at (nodes_size - 1);
	last ::= deref lastptr;
};

setup_delete_all ::= macro(action : parse_action) -> v0
{
	ret : parse_value mut := parse_value
	{
		.action := action;
		.offset := 0;
		.len := nodes_size;
		.nodes_size := 0;
	};
	defer return ret;
};

setup_delete_tail ::= macro(action : parse_action) -> v0
{
	ret : parse_value mut := parse_value
	{
		.action := action;
		.offset := 1;
		.len := nodes_size - 1;
		.nodes_size := 0;
	};
	defer return ret;
};
/////////////////////////////////////////////////////////////////////
//////////////////////// REDUCTION FUNCTIONS ////////////////////////
/////////////////////////////////////////////////////////////////////
commit_head ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.commit;
		.offset := 0;
		.len := 1;
	};
};

stash_head ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.stash;
		.offset := 0;
	};
};

stash_last ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.stash;
		.offset := nodes_size - 1;
	};
};

unstash_head ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.unstash;
		.offset := 0;
	};
};

unstash_last ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.unstash;
		.offset := nodes_size - 1;
	};
};

shift1 ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value{.action := parse_action.shift; .len := 1;};
};

shift2 ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value{.action := parse_action.shift; .len := 1;};
};

num2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(interpret_numeric_literal(src, tok.lexeme));
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

sym2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_symbol_expr(ast_symbol_expr
		{
			.symbol := src at (lex.off);
			.len := lex.len;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

char2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(ast_literal_expr
		{
			.type := ast_literal_type.char_literal;
			.chars := src at (lex.off);
			.chars_len := lex.len;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

str2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(ast_literal_expr
		{
			.type := ast_literal_type.string_literal;
			.chars := src at (lex.off);
			.chars_len := lex.len;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

expr2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.expr_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

decl2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.expr_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

tokenexpr2unop ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	// which token type at front?
	utok ::= first.utok;
	tok ::= utok.tok;
	unop_ty ::= ast_unop_type_from_token(tok.tok);
	if(unop_ty == -1)
	{
		return parse_value{.action := parse_action.error; .errmsg := "unrecognised unary operator";};
	}

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_unop_expr(ast_unop_expr{.type := unop_ty;});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	ast_unop_set_operand((ret.nodes) at 0, last, ar);
	(ret.nodes_size) = 1;
};

symcolsym2decl ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	// var name
	first_utok ::= first.utok;
	first_tok ::= first_utok.tok;
	first_lex ::= first_tok.lexeme;

	// type name
	last_utok ::= last.utok;
	last_tok ::= last_utok.tok;
	last_lex ::= last_tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.decl;
		.decl := ast_decl
		{
			.name := src at (first_lex.off);
			.name_len := first_lex.len;
			.typename := src at (last_lex.off);
			.typename_len := last_lex.off;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

grammar_stmtify ::= macro(nod : ast static, ru : grammar_rule) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, nod),
		token(lex_token.semicol),
		null_stash,
		pty.both,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, nod, token(lex_token.semicol)),
		null_lookahead,
		null_stash,
		pty.both,
		ru);
};

grammar_numeric_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.numeric_literal)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(num2expr));
};

grammar_symbol ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(sym2expr));
};

grammar_char_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.char_literal)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(char2expr));
};

grammar_string_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.string_literal)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(str2expr));
};

grammar_basic_decl ::= macro() -> v0
{
	// if a symbol is directly followed by a colon, its probably the start of a decl, so override before we exprify it.
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol)),
		token(lex_token.colon),
		null_stash,
		pty.both,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol), token(lex_token.colon)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol), token(lex_token.colon), token(lex_token.symbol)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(symcolsym2decl));
};

grammar_unop ::= macro(t : lex_token static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(t)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(stash_head));
};

grammar_unop_expr ::= macro(tok : lex_token static, exp : ast_expr_type static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		token(tok),
		pty.both,
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(tok), expr(exp)),
		null_lookahead,
		null_stash,
		pty.both,
		rule(tokenexpr2unop));
};

grammar_commit_stmt ::= macro(s : ast_stmt static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, stmt(s)),
		null_lookahead,
		null_stash,
		pty.head,
		rule(commit_head));
};

grammar_setup ::= func(a : arena mut&) -> v0
{
	psyc_timed(psyc_stage.setup);
	ar = a;
	parse_table_cap = 4096;
	parse_table = arena_push(a, __sizeof(deref parse_table) * parse_table_cap);
	__memset(parse_table, 0, __sizeof(deref parse_table) * parse_table_cap);

	my_nodes : ast mut#16;

	grammar_numeric_literal();
	grammar_symbol();
	grammar_char_literal();
	grammar_string_literal();

	grammar_basic_decl();

	grammar_unop(lex_token.dash);
	grammar_unop_expr(lex_token.dash, ast_expr_type.symbol);
	grammar_unop_expr(lex_token.dash, ast_expr_type.literal);
	grammar_unop_expr(lex_token.dash, ast_expr_type.biop);
	grammar_unop_expr(lex_token.dash, ast_expr_type.unop);
	grammar_unop_expr(lex_token.dash, ast_expr_type.callfunc);

	grammar_stmtify(expr(ast_expr_type.symbol), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.literal), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.biop), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.unop), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.callfunc), rule(expr2stmt));
	grammar_stmtify(node(ast_type.decl), rule(decl2stmt));

	grammar_commit_stmt(ast_stmt.expr_stmt);
	grammar_commit_stmt(ast_stmt.decl_stmt);
	grammar_commit_stmt(ast_stmt.region_stmt);
	grammar_commit_stmt(ast_stmt.struct_stmt);
	grammar_commit_stmt(ast_stmt.fn_stmt);
	grammar_commit_stmt(ast_stmt.blk_stmt);
};

== build ==
{
	add_source_file("stdlib/hash.psy");

	add_source_file("ast.psy");
	add_source_file("type.psy");
}
