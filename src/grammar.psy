ar : arena mut& mut;

hashnode ::= func(t : ast_type) -> u64
{
	v ::= (t@s64) * 1093;
	return hash(v);
};

hashtoken ::= func(t : lex_token) -> u64
{
	multiplier ::= (ast_type.unparsed_token)@s64 * 866820901;
	return multiplier ^ hash(t);
};

hashexpr ::= func(t : ast_expr_type) -> u64
{
	multiplier ::= (ast_type.expr)@s64 * 190299117;
	return multiplier ^ hash(t);
};

hashstmt ::= func(t : ast_stmt) -> u64
{
	multiplier ::= (ast_type.stmt)@s64 * 393505272299;
	return multiplier ^ hash(t);
};

hash_state ::= func(nodes : ast&, node_count : u64) -> u64
{
	i : u64 mut;
	hash : u64 mut := zero;
	for(i = 0, i < node_count, i = i + 1)
	{
		curnode ::= deref (nodes at i);
		istoken ::= (curnode.type) == (ast_type.unparsed_token);
		isexpr ::= (curnode.type) == (ast_type.expr);
		isstmt ::= (curnode.type) == (ast_type.stmt);
		if(istoken)
		{
			utok ::= curnode.utok;
			tokdata ::= utok.tok;
			hash = (hash ^ hashtoken(tokdata.tok));
		}
		if(isexpr)
		{
			expr ::= curnode.expr;
			hash = (hash ^ hashexpr(expr.type));
		}
		if(isstmt)
		{
			hash = (hash ^ hashstmt(curnode.stmt));
		}
		if(!istoken)
		{
			if(!isexpr)
			{
				if(!isstmt)
				{
					hash = (hash ^ hashnode(curnode.type));
				}
			}
		}
		hash = hash * 34875947865;
	}
	return hash;
};

parse_action ::= enum
{
	.invalid := 0;
	.reduce := 1;
	.shift := 2;
	.commit := 3;
	.stash := 4;
	.unstash := 5;
	.error := 6;
};

parse_value ::= struct
{
	action : parse_action;
	offset : u64;
	len : u64;
	errmsg : u8&;
	nodes : ast mut#16;
	nodes_size : u64;
};
grammar_rule ::= struct
{
	fn : func(source : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value;
	hash : u64;
};

default_rule_errmsg ::= "default rule invoked\n";
default_rule ::= func(source : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.error;
		.errmsg := default_rule_errmsg;
	};
};

[[private]]
parse_table : grammar_rule mut& mut;
[[private]]
parse_table_size : u64 mut;
[[private]]
parse_table_cap : u64 mut;

null_lookahead ::= zero@ast;
null_stash ::= zero@ast;
grammar_install_count : u64 mut;

grammar_install_impl ::= func(my_nodes : ast mut&, my_nodes_size : u64, nodes_count : u64, lookahead_node : ast, stash_node : ast, rule : grammar_rule) -> v0
{
	grammar_install_count = grammar_install_count + 1;
	hash : u64 mut := hash_state(my_nodes at 0, nodes_count);
	__memset(my_nodes at 0, 0, my_nodes_size);
	la ::= lookahead_node;
	la_hash : u64 mut := zero;
	if((la.type) != (ast_type.unknown))
	{
		la_hash = (!(hash_state(ref la, 1) ^ (202020202 * hash)));
		hash = (hash ^ la_hash);
	}
	st ::= stash_node;
	st_hash : u64 mut := zero;
	if((st.type) != (ast_type.unknown))
	{
		st_hash = (!(hash_state(ref st, 1) ^ (101010101 * hash)));
		hash = (hash ^ st_hash);
	}

	idx ::= hash % parse_table_cap;
	ptr : grammar_rule mut& mut := parse_table at idx;
	i : u64 mut := zero;
	while((ptr->fn) != null)
	{
		i = i + 1;
		ptr = (parse_table at ((idx + i) % parse_table_cap));
		if(i >= parse_table_cap)
		{
			psyc_panic(srcloc_current(), "ran out of space in the grammar rule hashtable");
		}
	}
	deref(ptr) = rule;
	(ptr->hash) = hash;
};

grammar_install ::= macro(nc : u64, la : ast, st : ast, r : grammar_rule) -> v0
{
	grammar_install_impl(my_nodes at 0, __sizeof(my_nodes), nc, la, st, r);
};

token ::= macro(t : lex_token) -> ast static
{
	yield ast
	{
		.type := ast_type.unparsed_token;
		.utok := ast_unparsed_token
		{
			.tok := token_data
			{
				.tok := t;
			};
		};
	};
};

node ::= macro(t : ast_type) -> ast static
{
	yield ast
	{
		.type := t;
	};
};

expr ::= macro(t : ast_expr_type) -> ast static
{
	yield ast
	{
		.type := ast_type.expr;
		.expr := ast_expr{.type := t;};
	};
};

stmt ::= macro(t : ast_stmt) -> ast static
{
	yield ast
	{
		.type := ast_type.stmt;
		.stmt := t;
	};
};

rule ::= macro(f : auto) -> grammar_rule
{
	yield grammar_rule{.fn := f;};
};

grammar_get_rule ::= func(hash : u64) -> grammar_rule
{
	idx ::= hash % parse_table_cap;
	ptr : grammar_rule mut& mut := parse_table at idx;
	i : u64 mut := zero;
	while((ptr->hash) != hash)
	{
		if((ptr->fn) == null)
		{
			return deref ptr;
		}
		i = i + 1;
		ptr = (parse_table at ((idx + i) % parse_table_cap));
		if(i >= parse_table_cap)
		{
			psyc_panic(srcloc_current(), "woopsey");
		}
	}
	return deref ptr;
};

// REDUCTION SETUP

setup_decls ::= macro() -> v0
{
	firstptr ::= nodes at 0;
	first ::= deref firstptr;
	lastptr ::= nodes at (nodes_size - 1);
	last ::= deref lastptr;
};

setup_delete_all ::= macro(action : parse_action) -> v0
{
	ret : parse_value mut := parse_value
	{
		.action := action;
		.offset := 0;
		.len := nodes_size;
		.nodes_size := 0;
	};
	defer return ret;
};

setup_delete_tail ::= macro(action : parse_action) -> v0
{
	ret : parse_value mut := parse_value
	{
		.action := action;
		.offset := 1;
		.len := nodes_size - 1;
		.nodes_size := 0;
	};
	defer return ret;
};
/////////////////////////////////////////////////////////////////////
//////////////////////// REDUCTION FUNCTIONS ////////////////////////
/////////////////////////////////////////////////////////////////////
commit_head ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.commit;
		.offset := 0;
		.len := 1;
	};
};

stash_head ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.stash;
		.offset := 0;
		.len := 0;
	};
};

stash_head_delete_all ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.stash;
		.offset := 0;
		.len := nodes_size - 1;
	};
};

stash_last ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.stash;
		.offset := nodes_size - 1;
		.len := 0;
	};
};

unstash_head ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.unstash;
		.offset := 0;
	};
};

unstash_last ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.unstash;
		.offset := nodes_size - 1;
	};
};

shift1 ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value{.action := parse_action.shift; .len := 1;};
};

shift2 ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value{.action := parse_action.shift; .len := 2;};
};

shift3 ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value{.action := parse_action.shift; .len := 3;};
};

swallow_all ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	return parse_value
	{
		.action := parse_action.reduce;
		.offset := 0;
		.len := nodes_size;
		.nodes_size := 0;
	};
};

num2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(interpret_numeric_literal(src, tok.lexeme));
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

sym2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_symbol_expr(ast_symbol_expr
		{
			.symbol := src at (lex.off);
			.len := lex.len;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

char2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(ast_literal_expr
		{
			.type := ast_literal_type.char_literal;
			.chars := src at (lex.off);
			.chars_len := lex.len;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

str2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(ast_literal_expr
		{
			.type := ast_literal_type.string_literal;
			.chars := src at (lex.off);
			.chars_len := lex.len;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

true2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(ast_literal_expr
		{
			.type := ast_literal_type.bool_literal;
			.boolean := true;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

false2expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_literal_expr(ast_literal_expr
		{
			.type := ast_literal_type.bool_literal;
			.boolean := false;
		});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

parenthesise_expr ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	// this is a more unique reduction
	// 3 nodes: (, expr, )
	// literally just return expr
	// we dont sensibly have a way to delete 2 separate spans of nodes, only one
	// so we will just delete them all and recreate the middle node.
	deref((ret.nodes) at 0) = deref(nodes at 1);
	(ret.nodes_size) = 1;
};

keywordret2retvoid ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := ast_expr
		{
			.type := ast_expr_type.ret;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

keywordretexpr2ret ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := ast_expr
		{
			.type := ast_expr_type.ret;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	ast_add_child((ret.nodes) at 0, last, ar);
	(ret.nodes_size) = 1;
};

expr2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.expr_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

decl2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.decl_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

fn2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.fn_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

struct2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.struct_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

region2stmt ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.region_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

tokenexpr2unop ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	// which token type at front?
	utok ::= first.utok;
	tok ::= utok.tok;
	unop_ty ::= ast_unop_type_from_token(tok.tok);
	if(unop_ty == -1)
	{
		return parse_value{.action := parse_action.error; .errmsg := "unrecognised unary operator";};
	}

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.expr;
		.expr := make_unop_expr(ast_unop_expr{.type := unop_ty;});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	ast_unop_set_operand((ret.nodes) at 0, last, ar);
	(ret.nodes_size) = 1;
};

deferstmt2unop ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.stmt;
		.stmt := ast_stmt.expr_stmt;
		.expr := make_unop_expr(ast_unop_expr{.type := ast_unop_type.op_defer;});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	ast_unop_set_operand((ret.nodes) at 0, last, ar);
	(ret.nodes_size) = 1;
};

exprtok2halfbiop ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	// expr *
	// make a biop with only one child
	// so we can stash it.
	second ::= deref(nodes at 1);
	utok ::= second.utok;
	tok ::= utok.tok;
	biop_ty ::= ast_biop_type_from_token(tok.tok);
	if(biop_ty == -1)
	{
		return parse_value{.action := parse_action.error; .errmsg := "unrecognised binary operator";};
	}

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.wipbiop;
		.expr := make_biop_expr(ast_biop_expr{.type := biop_ty;});
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	ast_biop_set_lhs((ret.nodes) at 0, first, ar);
	(ret.nodes_size) = 1;
};

wipbiop2biop ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);
	(firstptr->type) = (ast_type.expr);
	ast_biop_set_rhs(firstptr, last, ar);
};

symcolsym2decl ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	// var name
	first_utok ::= first.utok;
	first_tok ::= first_utok.tok;
	first_lex ::= first_tok.lexeme;

	// type name
	last_utok ::= last.utok;
	last_tok ::= last_utok.tok;
	last_lex ::= last_tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.decl;
		.decl := ast_decl
		{
			.name := src at (first_lex.off);
			.name_len := first_lex.len;
			.typename := src at (last_lex.off);
			.typename_len := last_lex.off;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

symcrap2deduceddecl ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	// var name
	first_utok ::= first.utok;
	first_tok ::= first_utok.tok;
	first_lex ::= first_tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.decl;
		.decl := ast_decl
		{
			.name := src at (first_lex.off);
			.name_len := first_lex.len;
			.typename := psyc_deduced_typename;
			.typename_len := cstrlen(psyc_deduced_typename);
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

declinitfunc2wipfn ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);
	decl ::= first.decl;
	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.wipfn_blue;
		.fn := ast_fn
		{
			.fn_name := decl.name;
			.fn_name_len := decl.name_len;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

wipfn_givereturn ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	utok ::= last.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	(firstptr->type) = (ast_type.wipfn_red);
	fn ::= ref(firstptr->fn);
	(fn->ret_typename) = src at (lex.off);
	(fn->ret_typename_len) = (lex.len);
	(firstptr->cursor_end) = (last.cursor_end);
};

wipfn2externfn ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.fn);
	(firstptr->cursor_end) = (last.cursor_end);
	fn ::= ref(firstptr->fn);
	(fn->is_extern) = true;
};

wipfn_awaitimplblock ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.wipfn_green);
	(firstptr->cursor_end) = (last.cursor_end);
};

wipfn2fn ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.fn);
	(firstptr->cursor_end) = (last.cursor_end);
	fn ::= ref(firstptr->fn);
	(fn->is_extern) = false;
};

symoparen2wipcall ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	utok ::= first.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.wipcall;
		.wipcall := ast_wipcall
		{
			.funcname := src at (lex.off);
			.funcname_len := lex.len;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

wipcallcparen2call ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);
	
	wipcall ::= first.wipcall;
	(firstptr->type) = (ast_type.expr);
	(firstptr->expr) = make_callfunc_expr(ast_callfunc_expr
	{
		.funcname := wipcall.funcname;
		.funcname_len := wipcall.funcname_len;
	});
	(firstptr->cursor_end) = (last.cursor_end);
};

declstruct2wipstruct ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	decl ::= first.decl;
	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.wipstruct;
		.structdef := ast_struct
		{
			.structname := decl.name;
			.structname_len := decl.name_len;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

wipstructcbrace2struct ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.structdef);
	(firstptr->cursor_end) = last.cursor_end;
};

cmpsymcmp2wipregion ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_all(parse_action.reduce);

	second ::= deref(nodes at 1);
	utok ::= second.utok;
	tok ::= utok.tok;
	lex ::= tok.lexeme;

	deref((ret.nodes) at 0) = ast
	{
		.type := ast_type.wipregion;
		.region := ast_region_stmt
		{
			.name := src at (lex.off);
			.name_len := lex.len;
		};
		.loc := first.loc;
		.cursor_begin := first.cursor_begin;
		.cursor_end := last.cursor_end;
		.children := null;
		.childcap := 0;
		.childcount := 0;
	};
	(ret.nodes_size) = 1;
};

wipregion2region ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);

	(firstptr->type) = (ast_type.region);
	(firstptr->cursor_end) = (last.cursor_end);
};

obracecbrace2blk ::= func(src : u8&, nodes : ast mut&, nodes_size : u64) -> parse_value
{
	setup_decls();
	setup_delete_tail(parse_action.reduce);
	(firstptr->type) = (ast_type.stmt);
	(firstptr->stmt) = (ast_stmt.blk_stmt);
	(firstptr->cursor_end) = (last.cursor_end);
};

grammar_stmtify ::= macro(nod : ast static, ru : grammar_rule) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, nod),
		token(lex_token.semicol),
		null_stash,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, nod, token(lex_token.semicol)),
		null_lookahead,
		null_stash,
		ru);
};

grammar_numeric_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.numeric_literal)),
		null_lookahead,
		null_stash,
		rule(num2expr));
};

grammar_symbol ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol)),
		null_lookahead,
		null_stash,
		rule(sym2expr));
};

grammar_char_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.char_literal)),
		null_lookahead,
		null_stash,
		rule(char2expr));
};

grammar_string_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.string_literal)),
		null_lookahead,
		null_stash,
		rule(str2expr));
};

grammar_bool_literal ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_true)),
		null_lookahead,
		null_stash,
		rule(true2expr));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_false)),
		null_lookahead,
		null_stash,
		rule(true2expr));
};

grammar_retvoid ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_return)),
		token(lex_token.semicol),
		null_stash,
		rule(keywordret2retvoid));
};

grammar_ret ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_return)),
		null_lookahead,
		null_stash,
		rule(stash_head));
};

grammar_ret_expr ::= macro(exp : ast_expr_type static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		token(lex_token.keyword_return),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_return), expr(exp)),
		null_lookahead,
		null_stash,
		rule(keywordretexpr2ret));
};

grammar_parenthesised ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.oparen)),
		null_lookahead,
		null_stash,
		rule(stash_head));
};

grammar_parenthesised_expr ::= macro(exp : ast_expr_type static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		token(lex_token.oparen),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.oparen), expr(exp)),
		token(lex_token.cparen),
		null_stash,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.oparen), expr(exp), token(lex_token.cparen)),
		null_lookahead,
		null_stash,
		rule(parenthesise_expr));
};

grammar_basic_decl ::= macro() -> v0
{
	// if a symbol is directly followed by a colon, its probably the start of a decl, so override before we exprify it.
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol)),
		token(lex_token.colon),
		null_stash,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol), token(lex_token.colon)),
		null_lookahead,
		null_stash,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol), token(lex_token.colon), token(lex_token.symbol)),
		null_lookahead,
		null_stash,
		rule(symcolsym2decl));
};

grammar_deduced_decl ::= macro() -> v0
{
	// name ::=
	// instantly becomes a decl with deduced typename
	// that way, the grammar rules with this initialiser and the normal decl initialiser can be shared.
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol), token(lex_token.colon)),
		token(lex_token.initialiser),
		null_stash,
		rule(symcrap2deduceddecl));
};

grammar_decl_init ::= macro(exp : ast_expr_type static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl)),
		token(lex_token.initialiser),
		null_stash,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl), token(lex_token.initialiser)),
		null_lookahead,
		null_stash,
		rule(stash_head_delete_all));

	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		node(ast_type.decl),
		rule(commit_head));

	// when should we unstash the decl?
	// when we see the following tokens:
	// ;
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.semicol)),
		null_lookahead,
		node(ast_type.decl),
		rule(unstash_head));
};

grammar_unop ::= macro(t : lex_token static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(t)),
		null_lookahead,
		null_stash,
		rule(stash_head));
};

grammar_unop_expr ::= macro(tok : lex_token static, exp : ast_expr_type static) -> v0
{
	// note: we unstash *as soon as* we see a valid expr.
	// this means that:
	// -5 + 12 => (-5) + 12
	// and not => -(5 + 12):
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		token(tok),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(tok), expr(exp)),
		null_lookahead,
		null_stash,
		rule(tokenexpr2unop));
};

grammar_biop ::= macro(exp : ast_expr_type static, tok : lex_token static) -> v0
{
	// basic setup
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		token(tok),
		null_stash,
		rule(shift1));
	
	// make halk biop
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp), token(tok)),
		null_lookahead,
		null_stash,
		rule(exprtok2halfbiop));

	// stash half biops
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipbiop)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	// unstash a half biop if an expression is ready
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		node(ast_type.wipbiop),
		rule(unstash_head));
	
	// half biop + expr => full biop
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipbiop), expr(exp)),
		null_lookahead,
		null_stash,
		rule(wipbiop2biop));

	// prevent decl initialisers from eating unfinished biops
	// shift instead of committing.
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		token(tok),
		node(ast_type.decl),
		rule(shift1));

	// prevent return statements from eating unfinished biops
	// shift instead of unstashing
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		token(tok),
		token(lex_token.keyword_return),
		rule(shift1));
};

grammar_wipfn ::= macro() -> v0
{
	// decl initialiser is func(...)
	// dont let it be stashed
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl), token(lex_token.initialiser)),
		token(lex_token.keyword_func),
		null_stash,
		rule(shift2));
	
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl), token(lex_token.initialiser), token(lex_token.keyword_func), token(lex_token.oparen)),
		null_lookahead,
		null_stash,
		rule(declinitfunc2wipfn));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_blue)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	// push decl as new function param
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl)),
		null_lookahead,
		node(ast_type.wipfn_blue),
		rule(commit_head));

	// todo: just eat a comma to handle multiple params?
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.comma)),
		null_lookahead,
		node(ast_type.wipfn_blue),
		rule(swallow_all));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.cparen)),
		token(lex_token.arrow),
		node(ast_type.wipfn_blue),
		rule(unstash_head));


	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_blue), token(lex_token.cparen)),
		token(lex_token.arrow),
		null_stash,
		rule(shift2));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_blue), token(lex_token.cparen), token(lex_token.arrow), token(lex_token.symbol)),
		null_lookahead,
		null_stash,
		rule(wipfn_givereturn));
};

grammar_fn_extern ::= macro() -> v0
{
	// wipfn_red has the whole signature now, and is followed by either:
	// (1) := extern (in which we will just set the function as extern and declare it complete)

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_red)),
		token(lex_token.initialiser),
		null_stash,
		rule(shift2));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_red), token(lex_token.initialiser), token(lex_token.keyword_extern)),
		null_lookahead,
		null_stash,
		rule(wipfn2externfn));
};

grammar_fn ::= macro() -> v0
{
	// (2) a obrace (in which case we have an implemention block incoming)
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_red)),
		token(lex_token.obrace),
		null_stash,
		rule(shift1));
	
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_red), token(lex_token.obrace)),
		null_lookahead,
		null_stash,
		rule(wipfn_awaitimplblock));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_green)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.cbrace)),
		null_lookahead,
		node(ast_type.wipfn_green),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipfn_green), token(lex_token.cbrace)),
		null_lookahead,
		null_stash,
		rule(wipfn2fn));
};

grammar_call ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol)),
		token(lex_token.oparen),
		null_stash,
		rule(shift1));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.symbol), token(lex_token.oparen)),
		null_lookahead,
		null_stash,
		rule(symoparen2wipcall));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipcall)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	// take exprs as params in grammar_call_param

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.comma)),
		null_lookahead,
		node(ast_type.wipcall),
		rule(swallow_all));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.cparen)),
		null_lookahead,
		node(ast_type.wipcall),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipcall), token(lex_token.cparen)),
		null_lookahead,
		null_stash,
		rule(wipcallcparen2call));
};

grammar_call_param ::= macro(exp : ast_expr_type static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, expr(exp)),
		null_lookahead,
		node(ast_type.wipcall),
		rule(commit_head));
};

grammar_struct ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl), token(lex_token.initialiser)),
		token(lex_token.keyword_struct),
		null_stash,
		rule(shift2));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.decl), token(lex_token.initialiser), token(lex_token.keyword_struct), token(lex_token.obrace)),
		null_lookahead,
		null_stash,
		rule(declstruct2wipstruct));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipstruct)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.cbrace)),
		token(lex_token.semicol),
		node(ast_type.wipstruct),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipstruct), token(lex_token.cbrace)),
		null_lookahead,
		null_stash,
		rule(wipstructcbrace2struct));
};

grammar_build_region ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.compare)),
		null_lookahead,
		null_stash,
		rule(shift3));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.compare), token(lex_token.symbol), token(lex_token.compare), token(lex_token.obrace)),
		null_lookahead,
		null_stash,
		rule(cmpsymcmp2wipregion));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipregion)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.cbrace)),
		null_lookahead,
		node(ast_type.wipregion),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.wipregion), token(lex_token.cbrace)),
		null_lookahead,
		null_stash,
		rule(wipregion2region));

	grammar_install(
		__arrcpy(ast, my_nodes, node(ast_type.region)),
		null_lookahead,
		null_stash,
		rule(region2stmt));

	grammar_install(
		__arrcpy(ast, my_nodes, stmt(ast_stmt.region_stmt)),
		null_lookahead,
		null_stash,
		rule(commit_head));
};

grammar_block ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.obrace)),
		null_lookahead,
		null_stash,
		rule(stash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.cbrace)),
		null_lookahead,
		token(lex_token.obrace),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.obrace), token(lex_token.cbrace)),
		null_lookahead,
		null_stash,
		rule(obracecbrace2blk));
};

grammar_defer ::= macro() -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_defer)),
		null_lookahead,
		null_stash,
		rule(stash_head));
};

grammar_defer_stmt ::= macro(s : ast_stmt static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, stmt(s)),
		null_lookahead,
		token(lex_token.keyword_defer),
		rule(unstash_head));

	grammar_install(
		__arrcpy(ast, my_nodes, token(lex_token.keyword_defer), stmt(s)),
		null_lookahead,
		null_stash,
		rule(deferstmt2unop));
};

grammar_commit_stmt ::= macro(s : ast_stmt static) -> v0
{
	grammar_install(
		__arrcpy(ast, my_nodes, stmt(s)),
		null_lookahead,
		null_stash,
		rule(commit_head));
};

grammar_setup ::= func(a : arena mut&) -> v0
{
	psyc_timed(psyc_stage.setup);
	ar = a;
	parse_table_cap = 1024;
	parse_table = arena_push(a, __sizeof(deref parse_table) * parse_table_cap);
	__memset(parse_table, 0, __sizeof(deref parse_table) * parse_table_cap);

	my_nodes : ast mut#16;

	grammar_numeric_literal();
	grammar_symbol();
	grammar_char_literal();
	grammar_string_literal();
	grammar_bool_literal();

	grammar_retvoid();
	grammar_ret();
	grammar_ret_expr(ast_expr_type.symbol);
	grammar_ret_expr(ast_expr_type.literal);
	grammar_ret_expr(ast_expr_type.biop);
	grammar_ret_expr(ast_expr_type.unop);
	grammar_ret_expr(ast_expr_type.callfunc);

	grammar_parenthesised();
	grammar_parenthesised_expr(ast_expr_type.symbol);
	grammar_parenthesised_expr(ast_expr_type.literal);
	grammar_parenthesised_expr(ast_expr_type.biop);
	grammar_parenthesised_expr(ast_expr_type.unop);
	grammar_parenthesised_expr(ast_expr_type.callfunc);
	grammar_parenthesised_expr(ast_expr_type.ret);

	grammar_basic_decl();
	grammar_deduced_decl();
	// note: you are going to want to add more reductions to decl_init
	// this is because they are going to break apart biops (and probably callfuncs)
	grammar_decl_init(ast_expr_type.symbol);
	grammar_decl_init(ast_expr_type.literal);
	grammar_decl_init(ast_expr_type.biop);
	grammar_decl_init(ast_expr_type.unop);
	grammar_decl_init(ast_expr_type.callfunc);

	// unary operators
	grammar_unop(lex_token.dash);
	grammar_unop_expr(lex_token.dash, ast_expr_type.symbol);
	grammar_unop_expr(lex_token.dash, ast_expr_type.literal);
	grammar_unop_expr(lex_token.dash, ast_expr_type.biop);
	grammar_unop_expr(lex_token.dash, ast_expr_type.unop);
	grammar_unop_expr(lex_token.dash, ast_expr_type.callfunc);

	// binary operators
	grammar_biop(ast_expr_type.symbol, lex_token.assign);
	grammar_biop(ast_expr_type.literal, lex_token.assign);
	grammar_biop(ast_expr_type.biop, lex_token.assign);
	grammar_biop(ast_expr_type.unop, lex_token.assign);
	grammar_biop(ast_expr_type.callfunc, lex_token.assign);

	grammar_biop(ast_expr_type.symbol, lex_token.plus);
	grammar_biop(ast_expr_type.literal, lex_token.plus);
	grammar_biop(ast_expr_type.biop, lex_token.plus);
	grammar_biop(ast_expr_type.unop, lex_token.plus);
	grammar_biop(ast_expr_type.callfunc, lex_token.plus);

	grammar_biop(ast_expr_type.symbol, lex_token.dash);
	grammar_biop(ast_expr_type.literal, lex_token.dash);
	grammar_biop(ast_expr_type.biop, lex_token.dash);
	grammar_biop(ast_expr_type.unop, lex_token.dash);
	grammar_biop(ast_expr_type.callfunc, lex_token.dash);

	grammar_biop(ast_expr_type.symbol, lex_token.asterisk);
	grammar_biop(ast_expr_type.literal, lex_token.asterisk);
	grammar_biop(ast_expr_type.biop, lex_token.asterisk);
	grammar_biop(ast_expr_type.unop, lex_token.asterisk);
	grammar_biop(ast_expr_type.callfunc, lex_token.asterisk);

	grammar_biop(ast_expr_type.symbol, lex_token.fslash);
	grammar_biop(ast_expr_type.literal, lex_token.fslash);
	grammar_biop(ast_expr_type.biop, lex_token.fslash);
	grammar_biop(ast_expr_type.unop, lex_token.fslash);
	grammar_biop(ast_expr_type.callfunc, lex_token.fslash);

	grammar_biop(ast_expr_type.symbol, lex_token.keyword_at);
	grammar_biop(ast_expr_type.literal, lex_token.keyword_at);
	grammar_biop(ast_expr_type.biop, lex_token.keyword_at);
	grammar_biop(ast_expr_type.unop, lex_token.keyword_at);
	grammar_biop(ast_expr_type.callfunc, lex_token.keyword_at);

	grammar_biop(ast_expr_type.symbol, lex_token.cast);
	grammar_biop(ast_expr_type.literal, lex_token.cast);
	grammar_biop(ast_expr_type.biop, lex_token.cast);
	grammar_biop(ast_expr_type.unop, lex_token.cast);
	grammar_biop(ast_expr_type.callfunc, lex_token.cast);

	// functions
	grammar_wipfn();
	grammar_fn_extern();
	grammar_fn();

	// callfuncs
	grammar_call();
	grammar_call_param(ast_expr_type.symbol);
	grammar_call_param(ast_expr_type.literal);
	grammar_call_param(ast_expr_type.biop);
	grammar_call_param(ast_expr_type.unop);
	grammar_call_param(ast_expr_type.callfunc);

	// structs
	grammar_struct();

	// make stmts (largest building blocks in program)
	grammar_stmtify(expr(ast_expr_type.symbol), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.literal), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.biop), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.unop), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.callfunc), rule(expr2stmt));
	grammar_stmtify(expr(ast_expr_type.ret), rule(expr2stmt));
	grammar_stmtify(node(ast_type.decl), rule(decl2stmt));
	grammar_stmtify(node(ast_type.fn), rule(fn2stmt));
	grammar_stmtify(node(ast_type.structdef), rule(struct2stmt));

	// build regions
	grammar_build_region();
	// block statements
	grammar_block();

	grammar_defer();
	grammar_defer_stmt(ast_stmt.expr_stmt);

	// commit all the statements to the final result (or a stashed node)
	grammar_commit_stmt(ast_stmt.expr_stmt);
	grammar_commit_stmt(ast_stmt.decl_stmt);
	grammar_commit_stmt(ast_stmt.region_stmt);
	grammar_commit_stmt(ast_stmt.struct_stmt);
	grammar_commit_stmt(ast_stmt.fn_stmt);
	grammar_commit_stmt(ast_stmt.blk_stmt);
};

== build ==
{
	add_source_file("stdlib/hash.psy");

	add_source_file("ast.psy");
	add_source_file("type.psy");
}
