parse_state : parse_data mut := zero;
parse_data ::= struct
{
	src : u8?;
	path : u8?;
	tokens : lex_state?;
	tokens_cursor : u64;
	nodes : ast mut[6];
	nodes_cursor : u64;
	lookahead : ast;
	
	stash : ast mut[64];
	stash_cursor : u64;

	root : ast mut;
};

token2ast ::= func(tok : token_data -> ast)
{
	l ::= tok.lexeme;
	return ast
	{
		.tag := ast_tag.unparsed_token;
		.utok := ast_unparsed_token{.tok := tok;};
		.begin_cursor := l.off;
		.end_cursor := l.off + (l.len);
		.loc := tok.begin;
		.children := zero;
		.children_count := zero;
		.children_cap := zero;
	};
};

parse_complete ::= func(-> bool)
{
	// parsing is done if:
	return
		// we've processed all the tokens
		(parse_state.tokens_cursor) >= (parse_state.tokens->tokens_size)
			&&
		// there are no nodes in our buffer
		(parse_state.nodes_cursor == 0)
			&&
		// the stash is empty
		(parse_state.stash_cursor == 0);
};

parse_current_key ::= func(include_lookahead : bool, include_stash : bool -> grammar_entry)
{
	key : grammar_entry mut := zero;

	i : u64 mut;
	for(i = 0, i < (parse_state.nodes_cursor), i = i + 1)
	{
		deref(key.uids # i) = ast_uid(parse_state.nodes # i);
	}
	if(include_lookahead)
	{
		key.lookahead = ast_uid(ref(parse_state.lookahead));
	}
	if(include_stash)
	{
		stashval : ast mut := zero;
		if(parse_state.stash_cursor > 0)
		{
			stashval = deref(parse_state.stash # (parse_state.stash_cursor - 1));
		}
		key.stash = ast_uid(ref(stashval));
	}
	return key;
};

parse_get_next_rule ::= func( -> grammar_rule)
{
	rule : grammar_rule mut := zero;

	// first try including both stash and lookahead
	rule = grammar_hashtable_lookup(parse_current_key(true, true));
	if(grammar_rule_invalid(rule))
	{
		// stash no lookahead
		rule = grammar_hashtable_lookup(parse_current_key(false, true));
	}
	if(grammar_rule_invalid(rule))
	{
		// lookahead no stash
		rule = grammar_hashtable_lookup(parse_current_key(true, false));
	}
	if(grammar_rule_invalid(rule))
	{
		// neither
		rule = grammar_hashtable_lookup(parse_current_key(false, false));
	}
	// if its invalid at this point then yes we're fugged.
	return rule;
};

parse_would_be_valid_if_extra_semicol ::= func(-> bool)
{
	old_lookahead ::= parse_state.lookahead;
	parse_state.lookahead = token2ast(token_data{.tok := lex_token.semicol;});
	would_be_invalid ::= grammar_rule_invalid(parse_get_next_rule());
	parse_state.lookahead = old_lookahead;
	return !would_be_invalid;
};

parse_print_state ::= func(-> v0)
{
	putchar(10);
	psyc_colour_reset();
	if(!(prog.compile_args.verbose_parse))
	{
		putzstr("to view the invalid AST, enable --verbose-parse");
		return;
	}
	putzstr("parse state (verbose)");
	putchar(10);

	putzstr("node stack:");
	putchar(10);
	i : u64 mut;
	for(i = 0, i < (parse_state.nodes_cursor), i = i + 1)
	{
		ast_verbose_print(deref(parse_state.nodes # i), 0);
	}

	if(parse_state.tokens_cursor <= (parse_state.tokens->tokens_size))
	{
		putzstr("lookahead:");
		putchar(10);
		ast_verbose_print(parse_state.lookahead, 0);
	}

	if(parse_state.stash_cursor > 0)
	{
		putzstr("stashtop:");
		putchar(10);
		ast_verbose_print(deref(parse_state.stash # 0), 0);
	}
};

parse_invalid_syntax_error ::= func(-> v0)
{
	front ::= parse_state.nodes # 0;
	psyc_error_begin(front->loc);
	putzstr("this code is not valid syntax ");
	if(parse_would_be_valid_if_extra_semicol())
	{
		putzstr("(hint: perhaps you need to add an extra semicolon)");
	}
	putzstr(":");
	putchar(10);

	ast_print_annotated_source(parse_state.src, front, parse_state.nodes_cursor);
	parse_print_state();
	psyc_diag_end();
	psyc_exit_failure();
};

parse_invoke_rule ::= func(rule : grammar_rule -> v0)
{
	result ::= rule.fn(parse_state.nodes # 0, parse_state.nodes_cursor);
	if(result.tag == (rule.shift))
	{
		shift(result.shift);
	}
	if(result.tag == (rule.reduce))
	{
		reduce(result.reduce);
	}
	if(result.tag == (rule.stash))
	{
		stash();
	}
	if(result.tag == (rule.unstash))
	{
		unstash();
	}
	if(result.tag == (rule.commit))
	{
		commit();
	}
	if(result.tag == zero)
	{
		psyc_panic_begin(zero);
		putzstr("malformed rule detected");
		psyc_diag_end();
		psyc_exit_failure();
	}

	// if our nodes_cursor is ever zero at this point we will automatically shift
	if(parse_state.nodes_cursor == 0)
	{
		shift(shift_data{.count := 1;});
	}
};

parse ::= func(file : source_file, lex : lex_state? -> ast)
{
	psyc_timed_begin(psyc_stage.parse);
	defer psyc_timed_end();

	if(lex->tokens_size == zero)
	{
		// empty source. return null ast
		return zero;
	}
	parse_state = zero;
	parse_state.root.loc = srcloc
	{
		.file := file.path;
		.line := 1;
		.column := 1;
	};
	parse_state.path = (file.path);
	parse_state.src = (file.src);
	parse_state.tokens = lex;
	parse_state.lookahead = token2ast(deref(lex->tokens # 0));
	parse_state.tokens_cursor = 1;
	ast_reserve_children(ref(parse_state.root), 1024, global_arena);

	shift(shift_data{.count := 1;});
	while(!parse_complete())
	{
		rule ::= parse_get_next_rule();
		if(grammar_rule_invalid(rule))
		{
			parse_invalid_syntax_error();
		}
		parse_invoke_rule(rule);
	}
	if(prog.compile_args.verbose_parse)
	{
		ast_verbose_print(parse_state.root, 0);
	}
	return parse_state.root;
};

shift ::= func(data : shift_data -> v0)
{
	n ::= data.count;
	// remember cursor points to lookahead so the end case is actually 'tokens_cursor == tokens_size + 1'
	if(parse_state.tokens_cursor > (parse_state.tokens->tokens_size))
	{
		return;
	}

	i : u64 mut;
	if((parse_state.nodes_cursor + n) > (__sizeof(parse_state.nodes) / __sizeof(deref(parse_state.nodes # 0))))
	{
		psyc_panic_begin(zero);
		putzstr("shifted beyond parser node capacity. increase parse_data.nodes array size or shift less stuff.");
		psyc_diag_end();
		psyc_exit_failure();
	}
	for(i = 0, i < n, i = i + 1)
	{
		// push current lookahead to the end of the list
		deref(parse_state.nodes # (parse_state.nodes_cursor)) = (parse_state.lookahead);
		parse_state.nodes_cursor = (parse_state.nodes_cursor + 1);
		parse_state.lookahead = token2ast(deref(parse_state.tokens->tokens # (parse_state.tokens_cursor)));
		parse_state.tokens_cursor = (parse_state.tokens_cursor + 1);
	}
};

reduce ::= func(data : reduce_data mut -> v0)
{
	num_new_nodes : u64 mut := 0;
	if(data.new_node.tag != zero)
	{
		num_new_nodes = 1;
		// write begin/end locs to new node automatically
		data.new_node.loc = ((parse_state.nodes # 0)->loc);
		data.new_node.begin_cursor = ((parse_state.nodes # 0)->begin_cursor);
		data.new_node.end_cursor = ((parse_state.nodes # (parse_state.nodes_cursor - 1))->end_cursor);
	}
	// how many are we deleting
	num_deleted_nodes : u64 mut := data.delete_count;
	if(num_deleted_nodes == -1)
	{
		num_deleted_nodes = (parse_state.nodes_cursor - (data.delete_offset));
	}

	nodes_diff ::= (num_deleted_nodes@s64) - (num_new_nodes@s64);
	if(nodes_diff < 0)
	{
		// adding more than we destroyed
		posdiff ::= -nodes_diff;
		ast_rotate_right(parse_state.nodes # 0, ref(parse_state.nodes_cursor), data.delete_offset, posdiff@u64);
		// this will stomp over old data but thats okay
		memcopy(parse_state.nodes # (data.delete_offset), ref(data.new_node), __sizeof(ast));
	}
	if(nodes_diff == 0)
	{
		// this is copying 1 node (if new_node.tag isnt zero)
		if(num_new_nodes > 0)
		{
			memcopy(parse_state.nodes # (data.delete_offset), ref(data.new_node), __sizeof(ast));
		}
		// or no copying at all if there is no new node (in which case this memcopy does nothing)
		
	}
	if(nodes_diff > 0)
	{
		// deleting more than we added
		ast_rotate_left(parse_state.nodes # 0, ref(parse_state.nodes_cursor), data.delete_offset, nodes_diff@u64);
		memcopy(parse_state.nodes # (data.delete_offset), ref(data.new_node), __sizeof(ast));
	}
};

stash ::= func(-> v0)
{
	if(parse_state.stash_cursor >= (__sizeof(parse_state.stash) / __sizeof(deref(parse_state.stash # 0))))
	{
		psyc_panic_begin(zero);
		putzstr("reached the absolute stash limit. submit a bug report or better yet jesus christ dont nest so much code!");
		psyc_diag_end();
		psyc_exit_failure();
	}
	stashptr ::= parse_state.stash # (parse_state.stash_cursor);
	parse_state.stash_cursor = (parse_state.stash_cursor + 1);

	deref(stashptr) = deref(parse_state.nodes # 0);
	// so im fairly certain the old impl was wrong - it was just copying the necessary node to the stash but not doing anything to the node array itself
	ast_rotate_left(parse_state.nodes # 0, ref(parse_state.nodes_cursor), 0, 1);
};

unstash ::= func(-> v0)
{
	// get the thing at the top of the stash
	if(parse_state.stash_cursor == 0)
	{
		psyc_panic_begin(zero);
		putzstr("unstash invoked on empty stash");
		psyc_diag_end();
		psyc_exit_failure();
	}
	parse_state.stash_cursor = (parse_state.stash_cursor - 1);
	stashptr ::= parse_state.stash # (parse_state.stash_cursor);
	ast_rotate_right(parse_state.nodes # 0, ref(parse_state.nodes_cursor), 0, 1);
	deref(parse_state.nodes # 0) = deref(stashptr);
	deref(stashptr) = zero;
};

commit ::= func(-> v0)
{
	// get the first node
	// if we have a stash, make it a child of stashtop
	// otherwise
	// make it a child of the root... simple as.
	parent : ast mut? mut := ref(parse_state.root);
	if(parse_state.stash_cursor >= 1)
	{
		parent = (parse_state.stash # (parse_state.stash_cursor - 1));
	}
	ast_add_child(parent, deref(parse_state.nodes # 0), global_arena);
	ast_rotate_left(parse_state.nodes # 0, ref(parse_state.nodes_cursor), 0, 1);
};

rule ::= enum
{
	.shift := 1;
	.reduce := 2;
	.stash := 3;
	.unstash := 4;
	.commit := 5;
};

shift_data ::= struct
{
	count : u64;
};

reduce_data ::= struct
{
	delete_offset : u64;
	delete_count : u64; // -1 means all
	// if new_node.tag == 0 it doesnt get added.
	new_node : ast;
};

reduce_delete_all_but_first ::= func(-> reduce_data)
{
	return reduce_data
	{
		.delete_offset := 1;
		.delete_count := -1;
		.new_node := zero;
	};
};

reduce_replace_all_with ::= func(new_node : ast -> reduce_data)
{
	return reduce_data
	{
		.delete_offset := 0;
		.delete_count := -1;
		.new_node := new_node;
	};
};

rule_result ::= struct
{
	tag : rule;
	shift : shift_data;
	reduce : reduce_data;
};
