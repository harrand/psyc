parse_state ::= struct
{
	lex : lex_state&;
	lex_cursor : u64 mut;

	node_array : ast mut&;
	node_array_cap : u64;
	node_array_size : u64;

	recursive_offset : u64 mut;
};

[[private]]
node_array_reserve ::= func(s : parse_state mut&, cap : u64) -> v0
{
	lex ::= s->lex;
	a ::= lex->ar;

	oldptr ::= s->node_array;
	oldcap ::= s->node_array_cap;

	(s->node_array_cap) = cap;
	(s->node_array) = arena_push(a, __sizeof(deref (s->node_array)) * (s->node_array_cap));
	if(oldptr != null)
	{
		__memcpy(s->node_array, oldptr, oldcap);
	}
};

[[private]]
node_array_add ::= func(s : parse_state mut&, node : ast) -> v0
{
	cap ::= s->node_array_cap;
	if((s->node_array_size) >= cap)
	{
		node_array_reserve(s, cap * 2);
	}

	deref((s->node_array) at (s->node_array_size)) = node;
	(s->node_array_size) = (s->node_array_size) + 1;
};

hash_state ::= func(nodes : ast&, node_count : u64) -> u64
{
	i : u64 mut;
	hash : u64 mut := zero;
	for(i = 0, i < node_count, i = i + 1)
	{
		curnode ::= deref (nodes at i);
		if((curnode.type) == (ast_type.unparsed_token))
		{
			utok ::= curnode.utok;
			tokdata ::= utok.tok;
			hash = (hash ^ token(tokdata.tok));
		}
		if((curnode.type) != (ast_type.unparsed_token))
		{
			hash = (hash ^ node(curnode.type));
		}
		hash = hash * 34875947865;
	}
	return hash;
};

parse_state_hash ::= func(s : parse_state mut&) -> u64
{
	return hash_state(s->node_array, s->node_array_size);
};

shift ::= func(s : parse_state mut&) -> v0
{
	// make unparsed token.
	lex ::= s->lex;
	tok ::= deref ((lex->tokens) at (s->lex_cursor));
	node_array_add(s, make_unparsed_token_ast(tok));
	(s->lex_cursor) = (s->lex_cursor) + 1;
};

parse_slice ::= alias lex_slice;

commit ::= func(s : parse_state mut&, nodes_to_commit : parse_slice) -> v0
{
	if((nodes_to_commit.off) == 0)
	{
		psyc_panic(srcloc_current(), "attempt to commit the 0th node (the root node)");
	}
	lex ::= s->lex;
	root ::= (s->node_array) at 0;
	i : u64 mut;
	for(i = 0, i < (nodes_to_commit.len), i = i + 1)
	{
		off ::= (nodes_to_commit.off) + i;
		cur ::= ((s->node_array) at off);
		ast_add_child(root, deref cur, lex->ar);
	}
	// remove children.
	(s->node_array_size) = (s->node_array_size) - (nodes_to_commit.len);
	offsetted_nodes_begin ::= (s->node_array) at (nodes_to_commit.off);
	offsetted_nodes_end ::= (s->node_array) at ((nodes_to_commit.off) + (nodes_to_commit.len));
	__memcpy(offsetted_nodes_begin, offsetted_nodes_end, __sizeof(ast) * (nodes_to_commit.len));
};

parse_complete ::= func(p : parse_state&) -> bool
{
	lex ::= p->lex;
	return (p->lex_cursor) >= (lex->tokens_size);
};

parse ::= func(lex : lex_state&, verbose_parse : bool) -> parse_state
{
	psyc_timed(psyc_stage.parse);
	root : ast mut := make_root_ast(lex->path);

	state : parse_state mut := zero;
	state.lex = lex;

	node_array_reserve(ref state, 1024);
	node_array_add(ref state, root);

	while(!parse_complete(ref state))
	{
		putuint(parse_state_hash(ref state));
		putchar(10);
		shift(ref state);
	}

	commit(ref state, parse_slice{.off := 2; .len := 3;});

	//ast_add_child(ref root, make_unparsed_token_ast(deref ((lex->tokens) at 0)), lex->ar);

	if(verbose_parse)
	{
		i : u64 mut;
		for(i = 0, i < (state.node_array_size), i = i + 1)
		{
			ast_verbose_print((state.node_array) at i, 0);
		}
	}

	return state;
};

== build ==
{
	add_source_file("lex.psy");
	add_source_file("diag.psy");
	add_source_file("hash.psy");
	add_source_file("grammar.psy");
}
