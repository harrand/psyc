rule_token_symbol2symbol_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	lexeme ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.symbol;
			.symbol := ast_symbol
			{
				.data := parse_state.src # (lexeme.off);
				.len := lexeme.len;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_stash ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.stash;
	};
};

rule_unstash ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.unstash;
	};
};

rule_shift1 ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.shift;
		.shift := shift_data{.count := 1;};
	};
};

rule_shift2 ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.shift;
		.shift := shift_data{.count := 2;};
	};
};

rule_commit ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.commit;
	};
};

rule_token_numeric_literal2literal_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	lexeme ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.literal;
			.literal := interpret_numeric_literal(parse_state.src, lexeme);
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_token_char_literal2literal_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	lexeme ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.literal;
			.literal := ast_literal
			{
				.tag := ast_literal_tag.char;
				.chars := parse_state.src # (lexeme.off);
				.chars_len := lexeme.len;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_token_string_literal2literal_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	lexeme ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.literal;
			.literal := ast_literal
			{
				.tag := ast_literal_tag.string;
				.chars := parse_state.src # (lexeme.off);
				.chars_len := lexeme.len;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_token_keyword_true2literal_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.literal;
			.literal := ast_literal
			{
				.tag := ast_literal_tag.boolean;
				.boolean := true;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_token_keyword_false2literal_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.literal;
			.literal := ast_literal
			{
				.tag := ast_literal_tag.boolean;
				.boolean := false;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_token_keyword_zero2literal_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.expr;
			.expr := ast_expr_tag.zero_value;
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_token_obrack_expr_token_cbrack2deref ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have [ expr ]
	// make it into a deref expr
	expr_node ::= deref(nodes # 1);
	deref_node ::= ast mut
	{
		.tag := ast_tag.expr;
		.expr := ast_expr_tag.dereference;
		.children := zero;
		.children_count := zero;
		.children_cap := zero;
	};
	ast_add_child(ref deref_node, expr_node, global_arena);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(deref_node);
	};
};

rule_token_symbol2typename_wip ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	name ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.typename;
			.typename := ast_typename
			{
				.tag := ast_typename_tag.wip;
				.quals := zero;
				.descriptor := ast_typename_descriptor.base;
				.basename := parse_state.src # (name.off);
				.basename_len := name.len;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_typename_wip2mut ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	typename_node ::= nodes # 0;
	typename_quals ::= ref(typename_node->typename.quals);
	deref(typename_quals) = (deref(typename_quals) | (tyqual.mut));
	typename_node->end_cursor = ((nodes # (nodes_count - 1))->end_cursor);
	// add tyqual.mut to the node
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_typename_wip2static ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	typename_node ::= nodes # 0;
	typename_quals ::= ref(typename_node->typename.quals);
	deref(typename_quals) = (deref(typename_quals) | (tyqual.static));
	typename_node->end_cursor = ((nodes # (nodes_count - 1))->end_cursor);
	// add tyqual.static to the node
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_typename_wip2weak ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	typename_node ::= nodes # 0;
	typename_quals ::= ref(typename_node->typename.quals);
	deref(typename_quals) = (deref(typename_quals) | (tyqual.weak));
	typename_node->end_cursor = ((nodes # (nodes_count - 1))->end_cursor);
	// add tyqual.weak to the node
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_typename_wip2ptr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// make the current first node an underlying type of a new typename node (pointer)
	underlying ::= deref(nodes # 0);
	ptr_node ::= ast mut
	{
		.tag := ast_tag.typename;
		.typename := ast_typename
		{
			.tag := ast_typename_tag.wip;
			.quals := zero;
			.descriptor := ast_typename_descriptor.pointer;
		};
		.children := zero;
		.children_count := zero;
		.children_cap := zero;
	};
	ast_add_child(ref ptr_node, underlying, global_arena);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ptr_node);
	};
};

rule_typename_wip2array_await_length ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	underlying ::= deref(nodes # 0);
	array_node ::= ast mut
	{
		.tag := ast_tag.typename;
		.typename := ast_typename
		{
			.tag := ast_typename_tag.array_await_length;
			.quals := zero;
			.descriptor := ast_typename_descriptor.array;
		};
		.children := zero;
		.children_count := zero;
		.children_cap := zero;
	};
	ast_add_child(ref array_node, underlying, global_arena);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(array_node);
	};
};

rule_typename_array_await_length_expr_token_semicol2wip ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	typename_node ::= nodes # 0;
	array_length_expr ::= deref(nodes # 1);
	// add the array length as another child (typename_node should already have a child which is the underlying type)
	// then set the tag to wip (incase it has more stuff afterwards)...
	ast_add_child(typename_node, array_length_expr, global_arena);
	typename_node->typename.tag = (ast_typename_tag.wip);
	typename_node->end_cursor = ((nodes # (nodes_count - 1))->end_cursor);
	
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_typename_wip2finalised ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	typename_node ::= nodes # 0;
	// make the typename finalised.
	typename_node->typename.tag = (ast_typename_tag.finalised);
	typename_node->end_cursor = ((nodes # (nodes_count - 1))->end_cursor);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_token_symbol_token_colon2decl_awaittype ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	name ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.decl;
			.decl := ast_decl
			{
				.tag := ast_decl_tag.await_type;
				.name := parse_state.src # (name.off);
				.name_len := name.len;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_decl_awaittype_typename_finalised2noinit ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// have a decl that awaits a typename
	// and a finalised typename
	// it's now a well-formed decl but without an init. we cant say the decl itself is finalised because we dont know if an initialisre is coming next so we will just say noinit for now.
	decl_node ::= nodes # 0;
	decl_node->decl.tag = (ast_decl_tag.noinit);
	ast_add_child(decl_node, deref(nodes # 1), global_arena);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_decl_noinit_token_initialiser2await_init_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// have a decl without an init followed by a :=
	// change its state to await_init_expr
	decl_node ::= nodes # 0;
	decl_node->decl.tag = (ast_decl_tag.await_init_expr);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_decl_noinit2finalised ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have a decl that is marked noinit
	// but it definitely isnt followed by an initialiser
	// we just mark it as finalised
	decl_node ::= nodes # 0;
	decl_node->decl.tag = (ast_decl_tag.finalised);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_token_symbol_token_colon_token_initialiser2decl_await_init_expr ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we are 'foo ::='
	// we want to convert this to a decl with 'deduced' descriptor typename and the 'await_init_expr' tag
	// this is the same as 'foo : xyz :='
	// so we can share that code
	name ::= (nodes # 0)->utok.tok.lexeme;
	new_decl_node : ast mut := ast
	{
		.tag := ast_tag.decl;
		.decl := ast_decl
		{
			.tag := ast_decl_tag.await_init_expr;
			.name := parse_state.src # (name.off);
			.name_len := name.len;
		};
		.children := zero;
		.children_count := zero;
		.children_cap := zero;
	};
	initialiser_node ::= (nodes # 2);
	// this is the typename
	ast_add_child(ref new_decl_node, ast
	{
		.tag := ast_tag.typename;
		.typename := ast_typename
		{
			.tag := ast_typename_tag.finalised;
			.descriptor := ast_typename_descriptor.deduced;
		};
		.begin_cursor := initialiser_node->begin_cursor;
		.end_cursor := initialiser_node->end_cursor;
		.loc := initialiser_node->loc;
		.children := zero;
		.children_count := zero;
		.children_cap := zero;
	}, global_arena);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(new_decl_node);
	};
};

rule_decl_await_init_expr_init_expr2finalised ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have a decl that awaits an init expr
	// followed by a finalised expr that the grammar says is a valid initialiser
	// shove it as a child and call it a day
	decl_node ::= nodes # 0;
	decl_node->decl.tag = (ast_decl_tag.finalised);
	ast_add_child(decl_node, deref(nodes # 1), global_arena);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_token_symbol_token_colon_token_initialiser_token_keyword_struct_token_obrace2structure_wip ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have a bunch of tokens
	// turn them into an empty struct so we can stash it and add members
	lexeme ::= (nodes # 0)->utok.tok.lexeme;
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_replace_all_with(ast
		{
			.tag := ast_tag.structure;
			.structure := ast_structure
			{
				.tag := ast_structure_tag.wip;
				.name := parse_state.src # (lexeme.off);
				.name_len := lexeme.len;
			};
			.children := zero;
			.children_count := zero;
			.children_cap := zero;
		});
	};
};

rule_structure_wip_token_cbrace2finalised ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have a struct_wip and a cbrace
	// just set the struct as finalised and swallow everything else
	structure_node ::= nodes # 0;
	structure_node->structure.tag = (ast_structure_tag.finalised);
	structure_node->end_cursor = ((nodes # (nodes_count - 1))->end_cursor);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_expr_token_semicol2stmt ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have an expr (of any particular tag) and a semicol
	expr_node ::= nodes # 0;
	(expr_node->tag) = (ast_tag.stmt);
	(expr_node->stmt) = (ast_stmt_tag.expr);
	last ::= nodes # (nodes_count - 1);
	expr_node->end_cursor = (last->end_cursor);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_decl_finalised_token_semicol2stmt ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have a finalised decl and a semicol
	decl_node ::= nodes # 0;
	(decl_node->tag) = (ast_tag.stmt);
	(decl_node->stmt) = (ast_stmt_tag.decl);
	last ::= nodes # (nodes_count - 1);
	decl_node->end_cursor = (last->end_cursor);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};

rule_structure_finalised_token_semicol2stmt ::= func(nodes : ast mut?, nodes_count : u64 -> rule_result)
{
	// we have a finalised structure and a semicol
	decl_node ::= nodes # 0;
	(decl_node->tag) = (ast_tag.stmt);
	(decl_node->stmt) = (ast_stmt_tag.structure);
	last ::= nodes # (nodes_count - 1);
	decl_node->end_cursor = (last->end_cursor);
	return rule_result
	{
		.tag := rule.reduce;
		.reduce := reduce_delete_all_but_first();
	};
};
