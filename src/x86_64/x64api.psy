x64api_t : struct
{
	prog : x64p mut;
	func_cursor : u64;
};

x64api : x64api_t mut := zero;

x64_add_func : func(abi : x64abi -> u64)
{
	if(x64api.prog.funcs == zero)
	{
		x64api.prog.funcs_cap = 8;
		x64api.prog.funcs = arena_alloc(global_arena, x64api.prog.funcs_cap * sizeof x64f);
	}
	while(x64api.prog.funcs_count >= x64api.prog.funcs_cap)
	{
		oldcap ::= x64api.prog.funcs_cap;
		old ::= x64api.prog.funcs;
		x64api.prog.funcs_cap = (x64api.prog.funcs_cap * 2);
		x64api.prog.funcs = arena_alloc(global_arena, x64api.prog.funcs_cap * sizeof x64f);
		memcopy(x64api.prog.funcs, old, oldcap * sizeof x64f);
	}
	idx ::= x64api.prog.funcs_count;
	x64api.prog.funcs_count = (x64api.prog.funcs_count + 1);
	[x64api.prog.funcs # idx] = x64f
	{
		.abi := abi;
		... := zero;
	};
	return idx;
};

x64_add_instruction : func(inst : x64i -> u64)
{
	fn ::= x64api.prog.funcs # (x64api.func_cursor);
	if(fn->inst == zero)
	{
		fn->inst_cap = 8;
		fn->inst = arena_alloc(global_arena, fn->inst_cap * sizeof x64i);
	}
	while(fn->inst_count >= fn->inst_cap)
	{
		oldcap ::= fn->inst_cap;
		old ::= fn->inst;
		fn->inst_cap = (fn->inst_cap * 2);
		fn->inst = arena_alloc(global_arena, fn->inst_cap * sizeof x64i);
		memcopy(fn->inst, old, oldcap * sizeof x64i);
	}
	idx ::= fn->inst_count;
	fn->inst_count = (fn->inst_count + 1);
	[fn->inst # idx] = inst;
	return idx;
};

x64_dump_to : func(ctx : dump_ctx mut? -> u64)
{
	return ctx_putx64p(ctx, x64api.prog);
};

// instructions api
x64_nop : func(-> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.nop;
		.operands := zero;
	});
};

x64_mov : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.mov;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

x64_push : func(op : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.push;
		.operands := x64v[4]
		{
			.0 := op;
			... := zero;
		};
	});
};

x64_pop : func(op : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.pop;
		.operands := x64v[4]
		{
			.0 := op;
			... := zero;
		};
	});
};

x64_cbw : func(-> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.cbw;
		.operands := zero;
	});
};

x64_cwde : func(-> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.cwde;
		.operands := zero;
	});
};

x64_cdqe : func(-> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.cdqe;
		.operands := zero;
	});
};

// increment r/m 8/16/32/64 by 1
x64_inc : func(op : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.inc;
		.operands := x64v[4]
		{
			.0 := op;
			... := zero;
		};
	});
};

// decrement r/m 8/16/32/64 by 1
x64_dec : func(op : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.dec;
		.operands := x64v[4]
		{
			.0 := op;
			... := zero;
		};
	});
};

// twos complement negate  r/m 8/16/32/64
x64_neg : func(op : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.neg;
		.operands := x64v[4]
		{
			.0 := op;
			... := zero;
		};
	});
};

// reverse each bit of  r/m 8/16/32/64
x64_not : func(op : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.not;
		.operands := x64v[4]
		{
			.0 := op;
			... := zero;
		};
	});
};

// store effective address for m in r 16/32/64
x64_lea : func(r : x64v, m : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.lea;
		.operands := x64v[4]
		{
			.0 := r;
			.1 := m;
			... := zero;
		};
	});
};

// add imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_add : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.add;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// sub imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_sub : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.sub;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// unsigned mul imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_mul : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.mul;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// signed mul imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_imul : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.imul;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// unsigned div imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_div : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.div;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// signed div imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_idiv : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.idiv;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// xor imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_xor : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.xor;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// or imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_or : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.or;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// and imm/r/m 8/16/32/64 (src) to r/m 8/16/32/64 (dst) and store the result in dst
x64_and : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.and;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// multiply r/m 8/16/32/64 (dst) by 2, imm8 times (src)
x64_shl : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.shl;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// multiply r/m 8/16/32/64 (dst) by 2, imm8 times (src)
// note: this is 100% completely identical to shl
x64_sal : func(dst : x64v, src : x64v -> v0)
{
	x64_shl(dst, src);
};

// unsigned divide r/m 8/16/32/64 (dst) by 2, imm8 times (src)
x64_shr : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.shr;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// signed divide r/m 8/16/32/64 (dst) by 2, imm8 times (src)
x64_sar : func(dst : x64v, src : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.sar;
		.operands := x64v[4]
		{
			.0 := dst;
			.1 := src;
			... := zero;
		};
	});
};

// call a addr/ripreladdr procedure
x64_call : func(callee : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.call;
		.operands := x64v[4]
		{
			.0 := callee;
			... := zero;
		};
	});
};

// unconditionally jump to a addr/ripreladdr location
x64_jmp : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jmp;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if zero/equal) to a addr/ripreladdr location
x64_jz : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jz;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if not zero/equal) to a addr/ripreladdr location
x64_jnz : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jnz;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if signed less) to a addr/ripreladdr location
x64_jl : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jl;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if signed less or equal) to a addr/ripreladdr location
x64_jle : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jle;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if signed greater) to a addr/ripreladdr location
x64_jg : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jg;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if signed greater or equal) to a addr/ripreladdr location
x64_jge : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jge;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if unsigned less) to a addr/ripreladdr location
x64_jb : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jb;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if unsigned less or equal) to a addr/ripreladdr location
x64_jbe : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jbe;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if unsigned greater) to a addr/ripreladdr location
x64_ja : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.ja;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if unsigned greater or equal) to a addr/ripreladdr location
x64_jae : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jae;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if sign bit is set i.e negative) to a addr/ripreladdr location
x64_js : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.js;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// jump (if overflow bit is set) to a addr/ripreladdr location
x64_jo : func(loc : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.jo;
		.operands := x64v[4]
		{
			.0 := loc;
			... := zero;
		};
	});
};

// logical compare. compute the bitwise AND of lhs r/m 8/16/32/64 and rhs r/imm 8/16/32/64. set SF, ZF, PF according to the result but do not affect the operands
x64_test : func(lhs : x64v, rhs : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.test;
		.operands := x64v[4]
		{
			.0 := lhs;
			.1 := rhs;
			... := zero;
		};
	});
};

// compute a subtraction of lhs r/m 8/16/32/64 and rhs r/m/imm 8/16/32/64 and set the status flags as if a SUB had occurred, but do not affect the operands.
x64_cmp : func(lhs : x64v, rhs : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.cmp;
		.operands := x64v[4]
		{
			.0 := lhs;
			.1 := rhs;
			... := zero;
		};
	});
};

x64_ret : func(-> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.ret;
		.operands := zero;
	});
};

// set r/m 8 if equal (ZF == 1)
x64_sete : func(b : x64v -> v0)
{
	x64_add_instruction(x64i
	{
		.tag := x64i_tag.sete;
		.operands := x64v[4]
		{
			.0 := b;
			... := zero;
		};
	});
};
