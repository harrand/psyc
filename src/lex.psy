Sleep ::= func(millis : s32) -> v0 := extern;

linefeed_size ::= func() -> u64
{
	if static(__is_windows)
	{
		return 2;
	}
	if static(__is_linux)
	{
		return 1;
	}
};

lex_slice ::= struct
{
	off : u64;
	len : u64;
};

impl_is_newline ::= func(char : u8) -> bool
{
	return char == 10;
};

impl_is_whitespace ::= func(char : u8) -> bool
{
	if(char == 0x20) // ' '
	{
		return true;
	}
	if(char == 0x0c) // '\f'
	{
		return true;
	}
	if(char == 0x0a) // '\n'
	{
		return true;
	}
	if(char == 0x0d) // '\r'
	{
		return true;
	}
	if(char == 0x09) // '/t'
	{
		return true;
	}
	if(char == 0x0b) // '/v'
	{
		return true;
	}
	return false;
};

impl_is_alpha ::= func(char : u8) -> bool
{
	if(char >= 'a')
	{
		if(char <= 'z')
		{
			return true;
		}
	}
	if(char >= 'A')
	{
		if(char <= 'Z')
		{
			return true;
		}
	}
	return false;
};

impl_starts_symbol ::= func(char : u8) -> bool
{
	if(impl_is_alpha(char))
	{
		return true;
	}
	if(char == '_')
	{
		return true;
	}
	return false;
};

impl_is_digit ::= func(char : u8) -> bool
{
	if(char >= '0')
	{
		if(char <= '9')
		{
			return true;
		}
	}
	return false;
};

impl_continues_symbol ::= func(char : u8) -> bool
{
	if(impl_is_digit(char))
	{
		return true;
	}
	if(char == '_')
	{
		return true;
	}
	if(impl_is_alpha(char))
	{
		return true;
	}
	return false;
};

impl_is_digit_or_period ::= func(char : u8) -> bool
{
	if(char == '.')
	{
		return true;
	}
	if(char >= '0')
	{
		if(char <= '9')
		{
			return true;
		}
	}
	return false;
};

impl_is_hexdigit ::= func(char : u8) -> bool
{
	if(impl_is_digit(char))
	{
		return true;
	}
	if(char >= 'a')
	{
		if(char <= 'f')
		{
			return true;
		}
	}
	if(char >= 'A')
	{
		if(char <= 'F')
		{
			return true;
		}
	}
	return false;
};

lex_token ::= enum
{
	.comment := 0;
	.multicomment := 1;
	.numeric_literal := 2;
	.symbol := 3;
	.char_literal := 4;
	.string_literal := 5;
	.semicol := 6;
	.initialiser := 7;
	.colon := 8;
	.comma := 9;
	.dot := 10;
	.compare := 11;
	.comparen := 12;
	.assign := 13;
	.arrow := 14;
	.oparen := 15;
	.cparen := 16;
	.obrace := 17;
	.cbrace := 18;
	.obrack := 19;
	.cbrack := 20;
	.plus := 21;
	.dash := 22;
	.asterisk := 23;
	.fslash := 24;
	.cast := 25;
	.arr := 26;
	.bitwise_and := 27;
	.bitwise_or := 28;
	.bitwise_exor := 29;
	.modulo := 30;
	.invert := 31;
	.loreq := 32;
	.goreq := 33;
	.oanglebrack := 34;
	.canglebrack := 35;
	.keyword_static_if := 36;
	.keyword_if := 37;
	.keyword_else := 38;
	.keyword_while := 39;
	.keyword_for := 40;
	.keyword_return := 41;
	.keyword_yield := 42;
	.keyword_func := 43;
	.keyword_macro := 44;
	.keyword_extern := 45;
	.keyword_struct := 46;
	.keyword_enum := 47;
	.keyword_ref := 48;
	.keyword_deref := 49;
	.keyword_atomic_deref := 50;
	.keyword_defer := 51;
	.keyword_alias := 52;
	.keyword_at := 53;
	.keyword_true := 54;
	.keyword_false := 55;
	.keyword_zero := 56;
	.keyword_null := 57;
};

token_data ::= struct
{
	tok : lex_token;
	lexeme : lex_slice;
	begin : srcloc;
	end : srcloc;
};

lex_state ::= struct
{
	path : u8&;
	src : u8&;
	cursor : u64;
	line : u64;
	col : u64;

	tokens : token_data mut&;
	tokens_size : u64;
	tokens_cap : u64;

	ar : arena mut&;
};

ls_current_loc ::= func(s : lex_state&) -> srcloc
{
	return srcloc
	{
		.file := (s->path);
		.function := "";
		.line := (s->line);
		.column := (s->col);
	};
};

td_print ::= func(s : lex_state&, tok : token_data) -> v0
{
	slice ::= tok.lexeme;
	puts(__enumname(tok.tok));
	putchar(' ');
	lexeme_data ::= (s->src) at (slice.off);
	j : u64 mut;
	for(j = 0, j < (slice.len), j = j + 1)
	{
		putchar(deref(lexeme_data at j));
	}
	putchar(' ');
	print_srcloc(tok.begin);
	putchar(10);
};

ls_advance ::= func(s : lex_state mut&, count : u32) -> v0
{
	i : u32 mut;
	cursor ::= (s->cursor)@_;
	for(i = 0, i < count, i = i + 1)
	{
		idx ::= cursor + i;
		is_newline ::= impl_is_newline(deref ((s->src) at idx));
		if(is_newline)
		{
			(s->line) = (s->line) + 1;
			(s->col) = 1;
		}
		if(!is_newline)
		{
			(s->col) = (s->col) + 1;
		}
		(s->cursor) = (s->cursor) + 1;
	}
};

ls_advance_str ::= func(s : lex_state mut&, str : u8&) -> v0
{
	ls_advance(s, cstrlen(str)@_);
};

ls_push_token ::= func(state : lex_state mut&, token : token_data) -> v0
{
	if((state->tokens) == null)
	{
		psyc_panic(srcloc_current(), "lex_state did not initialise its token list correctly. it was null.");
	}
	if((state->tokens_size) >= (state->tokens_cap))
	{
		oldcap ::= state->tokens_cap;
		old_tokens ::= state->tokens;

		(state->tokens_cap) = (state->tokens_cap) * 2;
		(state->tokens) = arena_push(state->ar, __sizeof(deref (state->tokens)) * (state->tokens_cap));
		__memcpy(state->tokens, old_tokens, __sizeof(deref (state->tokens)) * oldcap);
	}
	deref((state->tokens) at (state->tokens_size)) = token;
	(state->tokens_size) = (state->tokens_size) + 1;
};

tokenise_instruction ::= struct
{
	name : u8&;
	front_identifier : u8&;
	tokenise_fn : func(front : u8&, state : lex_state mut&) -> bool;
	trivial : bool;
	doesnt_affect_code : bool;
	allow_run_on : bool;
};

[[private]]
lex_instructions : tokenise_instruction mut#59;

[[private]]
impl_setup_instruction ::= func(tok : lex_token, inst : tokenise_instruction mut) -> v0
{
	inst.name = __enumname(tok);
	deref(lex_instructions at (tok@s64)) = inst;
};

[[private]]
impl_trivial_setup ::= func(tok : lex_token, front_identifier : u8&) -> v0
{
	impl_setup_instruction(tok, tokenise_instruction
	{
		.front_identifier := front_identifier;
		.tokenise_fn := null;
		.trivial := true;
		.doesnt_affect_code := true;
	});
};

[[private]]
tokenise_invalid ::= func(front : u8&, state : lex_state mut&) -> bool
{
	psyc_error(srcloc_current(), "asserty tokeniser function called. there is a bug in the lexer, or you didn't add support for a new lex token type.");
	psyc_panic(zero, front);
	return true;
};

[[private]]
tokenise_comment ::= func(front : u8&, state : lex_state mut&) -> bool
{
	// assume we already found '//' via front identifier.
	// just advance until we hit a newline.
	initial ::= state->cursor;
	beginloc ::= ls_current_loc(state);
	chars_left : u64 mut := cstrlen(state->src) - (state->cursor);
	i : u64 mut;
	for(i = 0, i < chars_left, i = i + 1)
	{
		is_newline ::= impl_is_newline(deref(front at i));
		if(!is_newline)
		{
			ls_advance(state, 1);
		}
		if(is_newline)
		{
			chars_left = 0;
		}
	}
	ls_push_token(state, token_data
	{
		.tok := lex_token.comment;
		.lexeme := lex_slice{.off := initial; .len := i - linefeed_size();};
		.begin := beginloc;
		.end := ls_current_loc(state);
	});
	return true;
};

[[private]]
tokenise_multicomment ::= func(front : u8&, state : lex_state mut&) -> bool
{
	// we're at /*
	// advance till we find '*/'
	initial ::= state->cursor;
	beginloc ::= ls_current_loc(state);
	offset_till_close ::= cstr_find(front, "*/");
	if(offset_till_close == -1)
	{
		return false;
	}
	ls_advance(state, offset_till_close@_);
	ls_advance_str(state, "*/");
	ls_push_token(state, token_data
	{
		.tok := lex_token.multicomment;
		.lexeme := lex_slice{.off := initial; .len := offset_till_close@_;};
		.begin := beginloc;
		.end := ls_current_loc(state);
	});
	return true;
};

[[private]]
tokenise_numeric_literal ::= func(front : u8&, state : lex_state mut&) -> bool
{
	myfront : u8& mut := front;
	is_hex_number ::= cstr_starts_with(front, "0x");
	f ::= deref(front at 0);
	starts_with_digit ::= impl_is_digit(f);
	starts_with_minus ::= f == '-';

	contains_decimal : bool mut := false;

	[[__force_mutable]]
	digit_checker : func(char : u8) -> bool := impl_is_digit_or_period;
	if(!is_hex_number)
	{
		if(!starts_with_digit)
		{
			if(!starts_with_minus)
			{
				return false;
			}
		}
	}

	initial ::= state->cursor;
	beginloc ::= ls_current_loc(state);
	if(is_hex_number)
	{
		// skip the 0x
		myfront = (myfront at 2);
		ls_advance_str(state, "0x");
		// remember - if we're lexing a hex literal then we also allow a-fA-F in our digits.
		digit_checker = impl_is_hexdigit;
	}
	if(starts_with_minus)
	{
		myfront = (myfront at 1);
		ls_advance_str(state, "-");
	}
	found_decimal : bool mut := false;
	while(digit_checker(deref(myfront at 0)))
	{
		if(deref(myfront at 0) == '.')
		{
			if(found_decimal)
			{
				psyc_fatal_error(ls_current_loc(state), "multiple decimal points detected in numeric literal");
			}
			found_decimal = true;
		}
		myfront = (myfront at 1);
		ls_advance(state, 1);
	}
	ls_push_token(state, token_data
	{
		.tok := lex_token.numeric_literal;
		.lexeme := lex_slice{.off := initial; .len := ((state->cursor) - initial);};
		.begin := beginloc;
		.end := ls_current_loc(state);
	});
	return true;
};

[[private]]
tokenise_symbol ::= func(front : u8&, state : lex_state mut&) -> bool
{
	myfront : u8& mut := front;
	if(!impl_starts_symbol(deref(myfront at 0)))
	{
		return false;
	}
	initial ::= state->cursor;
	beginloc ::= ls_current_loc(state);
	ls_advance(state, 1);
	myfront = (myfront at 1);
	while(impl_continues_symbol(deref(myfront at 0)))
	{
		ls_advance(state, 1);
		myfront = (myfront at 1);
	}
	ls_push_token(state, token_data
	{
		.tok := lex_token.symbol;
		.lexeme := lex_slice{.off := initial; .len := ((state->cursor) - initial);};
		.begin := beginloc;
		.end := ls_current_loc(state);
	});
	return true;
};

[[private]]
tokenise_char_literal ::= func(front : u8&, state : lex_state mut&) -> bool
{
	myfront : u8& mut := front;
	beginloc ::= ls_current_loc(state);
	ls_advance(state, 1);
	myfront = (myfront at 1);
	// we're at '
	// go until next '
	initial ::= state->cursor;
	off ::= cstr_find(myfront, "'");
	if(off == -1)
	{
		psyc_fatal_error(ls_current_loc(state), "could not find terminating single-quote ' in char literal");
	}
	ls_advance(state, off + 1);
	charlen ::= ((state->cursor) - initial - 1);
	if(charlen == 0)
	{
		psyc_fatal_error(ls_current_loc(state), "invalid char literal ''");
	}
	ls_push_token(state, token_data
	{
		.tok := lex_token.char_literal;
		.lexeme := lex_slice{.off := initial; .len := charlen;};
		.begin := beginloc;
		.end := ls_current_loc(state);
	});
	return true;
};

[[private]]
tokenise_string_literal ::= func(front : u8&, state : lex_state mut&) -> bool
{
	myfront : u8& mut := front;
	beginloc ::= ls_current_loc(state);
	ls_advance(state, 1);
	myfront = (myfront at 1);
	// we're at '
	// go until next '
	initial ::= state->cursor;
	strlit ::= "\"";
	off ::= cstr_find(myfront, strlit);
	if(off == -1)
	{
		psyc_fatal_error(ls_current_loc(state), "could not find terminating double-quote in string literal");
	}
	ls_advance(state, off + 1);
	strlen ::= ((state->cursor) - initial - 1);
	ls_push_token(state, token_data
	{
		.tok := lex_token.string_literal;
		.lexeme := lex_slice{.off := initial; .len := strlen;};
		.begin := beginloc;
		.end := ls_current_loc(state);
	});
	return true;
};

token_affects_code ::= func(tok : lex_token) -> bool
{
	inst ::= deref(lex_instructions at (tok@s64));
	return !(inst.doesnt_affect_code);
};

lex_setup ::= func() -> v0
{
	token_type_count ::= __sizeof(lex_instructions) / __sizeof(deref(lex_instructions at 0));
	i : u64 mut;

	// set them all to instructions that will assert.
	for(i = 0, i < token_type_count, i = i + 1)
	{
		deref(lex_instructions at i) = tokenise_instruction
		{
			.front_identifier := "";
			.tokenise_fn := tokenise_invalid;
			.trivial := false;
			.doesnt_affect_code := false;
			.allow_run_on := false;
		};
	}

	// manually populate them all. if we choose one thats wrong then the assert will go off.

	impl_setup_instruction(lex_token.comment, tokenise_instruction
	{
		.front_identifier := "//";
		.tokenise_fn := tokenise_comment;
		.trivial := false;
		.doesnt_affect_code := true;
	});

	impl_setup_instruction(lex_token.multicomment, tokenise_instruction
	{
		.front_identifier := "/*";
		.tokenise_fn := tokenise_multicomment;
		.trivial := false;
		.doesnt_affect_code := true;
	});

	impl_setup_instruction(lex_token.numeric_literal, tokenise_instruction
	{
		.front_identifier := null;
		.tokenise_fn := tokenise_numeric_literal;
		.trivial := false;
		.doesnt_affect_code := false;
	});

	impl_setup_instruction(lex_token.symbol, tokenise_instruction
	{
		.front_identifier := null;
		.tokenise_fn := tokenise_symbol;
		.trivial := false;
		.doesnt_affect_code := false;
	});

	impl_setup_instruction(lex_token.char_literal, tokenise_instruction
	{
		.front_identifier := "'";
		.tokenise_fn := tokenise_char_literal;
		.trivial := false;
		.doesnt_affect_code := false;
	});

	strlit ::= "\"";
	impl_setup_instruction(lex_token.string_literal, tokenise_instruction
	{
		.front_identifier := strlit;
		.tokenise_fn := tokenise_string_literal;
		.trivial := false;
		.doesnt_affect_code := false;
	});

	impl_trivial_setup(lex_token.semicol, ";");
	impl_trivial_setup(lex_token.initialiser, ":=");
	impl_trivial_setup(lex_token.colon, ":");
	impl_trivial_setup(lex_token.comma, ",");
	impl_trivial_setup(lex_token.dot, ".");
	impl_trivial_setup(lex_token.compare, "==");
	impl_trivial_setup(lex_token.comparen, "!=");
	impl_trivial_setup(lex_token.assign, "=");
	impl_trivial_setup(lex_token.arrow, "->");
	impl_trivial_setup(lex_token.oparen, "(");
	impl_trivial_setup(lex_token.cparen, ")");
	impl_trivial_setup(lex_token.obrace, "{");
	impl_trivial_setup(lex_token.cbrace, "}");
	impl_trivial_setup(lex_token.obrack, "[");
	impl_trivial_setup(lex_token.cbrack, "]");
	impl_trivial_setup(lex_token.plus, "+");
	impl_trivial_setup(lex_token.dash, "-");
	impl_trivial_setup(lex_token.asterisk, "*");
	impl_trivial_setup(lex_token.fslash, "/");
	impl_trivial_setup(lex_token.cast, "@");
	impl_trivial_setup(lex_token.arr, "#");
	impl_trivial_setup(lex_token.bitwise_and, "&");
	impl_trivial_setup(lex_token.bitwise_or, "|");
	impl_trivial_setup(lex_token.bitwise_exor, "^");
	impl_trivial_setup(lex_token.modulo, "%");
	impl_trivial_setup(lex_token.invert, "!");
	impl_trivial_setup(lex_token.loreq, "<=");
	impl_trivial_setup(lex_token.goreq, ">=");
	impl_trivial_setup(lex_token.oanglebrack, "<");
	impl_trivial_setup(lex_token.canglebrack, ">");
	impl_trivial_setup(lex_token.keyword_static_if, "if static");
	impl_trivial_setup(lex_token.keyword_if, "if");
	impl_trivial_setup(lex_token.keyword_else, "else");
	impl_trivial_setup(lex_token.keyword_while, "while");
	impl_trivial_setup(lex_token.keyword_for, "for");
	impl_trivial_setup(lex_token.keyword_return, "return");
	impl_trivial_setup(lex_token.keyword_yield, "yield");
	impl_trivial_setup(lex_token.keyword_func, "func");
	impl_trivial_setup(lex_token.keyword_macro, "macro");
	impl_trivial_setup(lex_token.keyword_extern, "extern");
	impl_trivial_setup(lex_token.keyword_struct, "struct");
	impl_trivial_setup(lex_token.keyword_enum, "enum");
	impl_trivial_setup(lex_token.keyword_ref, "ref");
	impl_trivial_setup(lex_token.keyword_deref, "deref");
	impl_trivial_setup(lex_token.keyword_atomic_deref, "atomic deref");
	impl_trivial_setup(lex_token.keyword_defer, "defer");
	impl_trivial_setup(lex_token.keyword_alias, "alias");
	impl_trivial_setup(lex_token.keyword_at, "at");
	impl_trivial_setup(lex_token.keyword_true, "true");
	impl_trivial_setup(lex_token.keyword_false, "false");
	impl_trivial_setup(lex_token.keyword_zero, "zero");
	impl_trivial_setup(lex_token.keyword_null, "null");
};

ls_verbose_print ::= func(s : lex_state&) -> v0
{
	puts(s->src);
	// just print out all token datas.
	i : u64 mut;
	for(i = 0, i < (s->tokens_size), i = i + 1)
	{
		tok ::= deref ((s->tokens) at i);
		td_print(s, tok);
	}
};

try_tokenise ::= func(state : lex_state mut&) -> bool
{
	token_type_count ::= __sizeof(lex_instructions) / __sizeof(deref(lex_instructions at 0));
	i : u64 mut;

	while(impl_is_whitespace(deref((state->src) at (state->cursor))))
	{
		is_newline ::= impl_is_newline(deref((state->src) at (state->cursor)));
		if(is_newline)
		{
			(state->line) = (state->line) + 1;
			(state->col) = 1;
		}
		if(!is_newline)
		{
			(state->col) = (state->col) + 1;
		}
		(state->cursor) = (state->cursor) + 1;
	}
	if((state->cursor) >= cstrlen(state->src))
	{
		// we are out of chars to lex.
		return false;
	}
	front ::= (state->src) at (state->cursor);

	for(i = 0, i < token_type_count, i = i + 1)
	{
		instruction ::= deref(lex_instructions at i);
		if(instruction.trivial)
		{
			// its trivial. do trivial lexing.
			if(cstr_starts_with(front, instruction.front_identifier))
			{
				// match!
				initial ::= state->cursor;
				loc ::= ls_current_loc(state);
				ls_advance_str(state, instruction.front_identifier);
				endloc ::= ls_current_loc(state);
				// todo: not zero!
				ls_push_token(state, token_data
				{
					.tok := i@lex_token;
					.lexeme := lex_slice{.off := initial; .len := (state->cursor) - initial;};
					.begin := loc;
					.end := endloc;
				});
				return true;
			}
		}
		if(!(instruction.trivial))
		{
			// its not trivial. we must have a tokeniser_fn.
			tokfn ::= instruction.tokenise_fn;
			if(tokfn == null)
			{
				psyc_panic(srcloc_current(), "non-trivial instruction did not have a tokeniser function");
				__debugbreak();
			}
			if((instruction.front_identifier) == null)
			{
				if(tokfn(front, state))
				{
					return true;
				}
			}
			if((instruction.front_identifier) != null)
			{
				if(cstr_starts_with(front, instruction.front_identifier))
				{
					tokfn(front, state);
					return true;
				}
			}
		}
	}
	psyc_panic(srcloc_current(), "failed to lex");
	return true;
};

lex ::= func(path : u8&, src : u8&, a : arena mut&, verbose_lex : bool) -> lex_state
{
	psyc_timed(psyc_stage.lex);
	ret : lex_state mut := zero;
	(ret.line) = 1;
	(ret.col) = 1;
	(ret.path) = path;
	(ret.src) = src;
	(ret.tokens_cap) = 1024;
	(ret.tokens) = arena_push(a, __sizeof(deref (ret.tokens)) * (ret.tokens_cap));
	(ret.ar) = a;
	len ::= cstrlen(src);

	while((ret.cursor) < len@_)
	{
		try_tokenise(ref ret);
	}

	if(verbose_lex)
	{
		ls_verbose_print(ref ret);
	}
	return ret;
};

== build ==
{
	add_source_file("diag.psy");
}
