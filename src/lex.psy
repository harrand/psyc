lexar : arena mut& mut;

impl_is_whitespace ::= func(char : u8) -> bool
{
	if(char == 0x20) // ' '
	{
		return true;
	}
	if(char == 0x0c) // '\f'
	{
		return true;
	}
	if(char == 0x0a) // '\n'
	{
		return true;
	}
	if(char == 0x0d) // '\r'
	{
		return true;
	}
	if(char == 0x09) // '/t'
	{
		return true;
	}
	if(char == 0x0b) // '/v'
	{
		return true;
	}
	return false;
};

impl_starts_symbol ::= func(char : u8) -> bool
{

	if(char >= 'a')
	{
		if(char <= 'z')
		{
			return true;
		}
	}
	if(char >= 'A')
	{
		if(char <= 'Z')
		{
			return true;
		}
	}
	if(char == '_')
	{
		return true;
	}
	return false;
};

impl_could_continue_symbol ::= func(ch : u8) -> bool
{
	if(ch >= '0')
	{
		if(ch <= '9')
		{
			return true;
		}
	}
	if(ch == '_')
	{
		return true;
	}
	if(ch == '&')
	{
		return true;
	}
	if(ch >= 'a')
	{
		if(ch <= 'z')
		{
			return true;
		}
	}
	if(ch >= 'A')
	{
		if(ch <= 'Z')
		{
			return true;
		}
	}
	if(ch == '[')
	{
		return true;
	}
	if(ch == ']')
	{
		return true;
	}
	return false;
};

impl_is_punctuation ::= func(ch : u8) -> bool
{
	if(ch >= 'a')
	{
		if(ch <= 'z')
		{
			return false;
		}
	}
	if(ch >= 'A')
	{
		if(ch <= 'Z')
		{
			return false;
		}
	}
	if(ch >= '0')
	{
		if(ch <= '9')
		{
			return false;
		}
	}
	return true;
};

lex_token ::= enum
{
	.numeric_literal := 2;
	.char_literal := 3;
	.string_literal := 4;
	.semicol := 5;
	.initialiser := 6;
	.colon := 7;
	.comma := 8;
	.dot := 9;
	.compare := 10;
	.comparen := 11;
	.assign := 12;
	.arrow := 13;
	.oparen := 14;
	.cparen := 15;
	.obrace := 16;
	.cbrace := 17;
	.obrack := 18;
	.cbrack := 19;
	.plus := 20;
	.dash := 21;
	.asterisk := 22;
	.fslash := 23;
	.cast := 24;
	.arr := 25;
	.logical_and := 26;
	.bitwise_and := 27;
	.logical_or := 28;
	.bitwise_or := 29;
	.bitwise_exor := 30;
	.modulo := 31;
	.bitwise_invert := 32;
	.logical_invert := 33;
	.loreq := 34;
	.goreq := 35;
	.oanglebrack2 := 36;
	.canglebrack2 := 37;
	.oanglebrack := 38;
	.canglebrack := 39;
	.keyword_static_if := 40;
	.keyword_if := 41;
	.keyword_else := 42;
	.keyword_while := 43;
	.keyword_for := 44;
	.keyword_return := 45;
	.keyword_yield := 46;
	.keyword_func := 47;
	.keyword_macro := 48;
	.keyword_extern := 49;
	.keyword_struct := 50;
	.keyword_enum := 51;
	.keyword_ref := 52;
	.keyword_deref := 53;
	.keyword_atomic_deref := 54;
	.keyword_defer := 55;
	.keyword_alias := 56;
	.keyword_at := 57;
	.keyword_true := 58;
	.keyword_false := 59;
	.keyword_zero := 60;
	.symbol := 61;
};

lex_slice ::= struct
{
	off : u64;
	len : u64;
};

token_data ::= struct
{
	tok : lex_token;
	lexeme : lex_slice;
	begin : srcloc;
	end : srcloc;
};

lex_entry_tag ::= enum
{
	.none := 1;
	// data is the token type you have just found.
	.success := 2;
	// forget what you're doing, dont backtrack and start again (you've lexed a comment most likely)
	.discard := 3;
};

lex_entry ::= struct
{
	tag : lex_entry_tag;
	data : u64;
	metadata : u64 weak;
	name : u8&;
	next : v0&;
};

lex_table ::= struct
{
	tbl : lex_entry mut#255;
};

main_table : lex_table mut;

symbol_continuation_table : lex_table mut;

lex_internal_state ::= struct
{
	begin_cursor : u64;
	begin_loc : srcloc;
	tbl : lex_table&;
};

lex_state ::= struct
{
	path : u8&;
	src : u8&;
	cursor : u64;
	line : u64;
	col : u64;

	tokens : token_data mut&;
	tokens_size : u64;
	tokens_cap : u64;

	internal : lex_internal_state;
};

td_print ::= func(s : lex_state&, tok : token_data) -> v0
{
	slice ::= tok.lexeme;
	puts(__enumname(tok.tok));
	putchar(' ');
	lexeme_data ::= (s->src) at (slice.off);
	j : u64 mut;
	for(j = 0, j < (slice.len), j = j + 1)
	{
		putchar(deref(lexeme_data at j));
	}
	putchar(' ');
	print_srcloc(tok.begin);
	putchar(10);
};

ls_current_loc ::= func(s : lex_state&) -> srcloc
{
	return srcloc
	{
		.file := (s->path);
		.function := "";
		.line := (s->line);
		.column := (s->col);
	};
};

lex_newtable ::= func() -> lex_table mut&
{
	ret : lex_table mut& := arena_push(lexar, __sizeof(lex_table));
	__memset(ret, 0, __sizeof(lex_table));
	return ret;
};

lex_break_type ::= enum
{
	.punctuation := 1;
	.whitespace := 2;
	.not_equals_symbol := 4;
};

matches_break_type ::= func(break : lex_break_type, ch : u8) -> bool
{
	matches : bool mut := false;
	if((break & (lex_break_type.punctuation)) != zero)
	{
		if(impl_is_punctuation(ch))
		{
			matches = true;
		}
	}
	if((break & (lex_break_type.whitespace)) != zero)
	{
		if(impl_is_whitespace(ch))
		{
			matches = true;
		}
	}
	if((break & (lex_break_type.not_equals_symbol)) != zero)
	{
		if(ch == '=')
		{
			matches = false;
		}
	}
	return matches;
};

lex_install ::= func(t : lex_token, front_identifier : u8&, break : lex_break_type) -> v0
{
	// for each char 'c' in the front identifier:
	// take entry 'e' from index 'c' at the current table and look at its tag
	//		- if its 'zero', then overwrite it to .none and create a new table and point e->next to it.
	//		- if its .none, then it redirects to another table already, we just move on
	//		- if its .success, then we move on, unless it doesnt have a ->next in which case we make one and then move on.
	//		- if its .discard, then overwrite it to .none and create a new table and point e->next to it.
	//	e = e->next
	// when we run out of chars, we are left with the final entry of e
	// if 'need_punc_next' is false, then we look at e again.
	//		- if its .success, we probably have duplicate lex rules and we should assert
	//		- in all other cases, overwrite it to .success with the data being the given lex token.

	len : u64 mut := cstrlen(front_identifier);
	if(break == zero)
	{
		len = len - 1;
	}
	tbl : lex_table mut& mut := ref main_table;
	i : u64 mut;
	c : u8 mut;
	e : lex_entry mut& mut;
	newtbl : lex_table mut& mut;
	for(i = 0, i < len, i = i + 1)
	{
		c = deref(front_identifier at i);
		e = ((tbl->tbl) at c);
		if((e->tag) == (lex_entry_tag.success))
		{
			newtbl = lex_newtable();
			if((e->next) == zero)
			{
				(e->next) = (newtbl@v0&);
			}
		}
		if((e->tag) == (lex_entry_tag.none))
		{
		}
		if((e->tag) == (lex_entry_tag.discard))
		{
			newtbl = lex_newtable();
			(deref e) = lex_entry
			{
				.tag := lex_entry_tag.none;
				.data := zero;
				.metadata := zero;
				.name := "";
				.next := newtbl@v0&;
			};
		}
		if((e->tag) == zero)
		{
			newtbl = lex_newtable();
			(deref e) = lex_entry
			{
				.tag := lex_entry_tag.none;
				.data := zero;
				.metadata := zero;
				.name := "";
				.next := newtbl@v0&;
			};
		}
		tbl = ((e->next)@lex_table mut&);
	}

	if(break == zero)
	{
		last ::= deref(front_identifier at len);
		e = ((tbl->tbl) at last);
		if((e->tag) == (lex_entry_tag.success))
		{
			psyc_error_begin(zero);
			puts(".success entry for lex_token.");
			puts(__enumname(t));
			puts(" steps on the .success entry for lex_token.");
			puts(__enumname((e->data)@lex_token));
			puts(" - do they have the exact same front identifier?");
			psyc_diag_end();
			psyc_exit_failure();
		}
		(deref e) = lex_entry
		{
			.tag := lex_entry_tag.success;
			.data := t@s64@u64;
			.metadata := false;
			.name := "";
			.next := zero;
		};
	}
	if(break != zero)
	{
		winning_entry ::= lex_entry
		{
			.tag := lex_entry_tag.success;
			.data := t@s64@u64;
			.metadata := true;
			.name := "";
			.next := zero;
		};
		for(i = 0, i < 255, i = i + 1)
		{
			final ::= (tbl->tbl) at i;
			fnext ::= final->next;
			if(matches_break_type(break, i@u8))
			{
				(deref final) = winning_entry;
				(final->next) = fnext;
			}
		}
	}
};

lex_setup ::= func(a : arena mut&) -> v0
{
	psyc_timed(psyc_stage.setup);
	lexar = a;

	whitespace ::= (lex_break_type.whitespace);
	whitespace_and_punctuation ::= (lex_break_type.whitespace) | (lex_break_type.punctuation);
	//ls_table_set_fn(ref main_table, '_', testfn);
	lex_install(lex_token.semicol, ";", zero);
	lex_install(lex_token.initialiser, ":=", zero);
	lex_install(lex_token.colon, ":", whitespace_and_punctuation | (lex_break_type.not_equals_symbol));
	lex_install(lex_token.keyword_func, "func", whitespace_and_punctuation);
	lex_install(lex_token.arrow, "->", zero);
	lex_install(lex_token.keyword_extern, "extern", whitespace_and_punctuation);
	lex_install(lex_token.keyword_true, "true", whitespace_and_punctuation);
};

ls_verbose_print ::= func(s : lex_state&) -> v0
{
	puts(s->path);
	putchar(':');
	putchar(10);
	putchar('{');
	putchar(10);
	// just print out all token datas.
	i : u64 mut;
	for(i = 0, i < (s->tokens_size), i = i + 1)
	{
		tok ::= deref ((s->tokens) at i);
		td_print(s, tok);
	}
	putchar('}');
	putchar(10);
};

ls_push_token ::= func(state : lex_state mut&, token : token_data) -> v0
{
	if((state->tokens) == null)
	{
		psyc_panic(srcloc_current(), "lex_state did not initialise its token list correctly. it was null.");
	}
	if((state->tokens_size) >= (state->tokens_cap))
	{
		oldcap ::= state->tokens_cap;
		old_tokens ::= state->tokens;

		(state->tokens_cap) = (state->tokens_cap) * 2;
		(state->tokens) = arena_push(lexar, __sizeof(deref (state->tokens)) * (state->tokens_cap));
		__memcpy(state->tokens, old_tokens, __sizeof(deref (state->tokens)) * oldcap);
	}
	deref((state->tokens) at (state->tokens_size)) = token;
	(state->tokens_size) = (state->tokens_size) + 1;
};

lex_advance ::= func(s : lex_state mut&) -> v0
{
	whitespace ::= deref((s->src) at (s->cursor)) == 10;
	if(whitespace)
	{
		(s->line) = (s->line) + 1;
		(s->col) = 1;
	}
	if(!whitespace)
	{
		(s->col) = (s->col) + 1;
	}
	(s->cursor) = (s->cursor) + 1;
};

lex_get ::= func(s : lex_state mut&) -> lex_entry mut&
{
	// get the next char
	char ::= deref ((s->src) at (s->cursor));

	internal ::= ref(s->internal);
	if((internal->tbl) == zero)
	{
		// we are starting again
		(internal->tbl) = (ref main_table);
		(internal->begin_cursor) = (s->cursor);
		(internal->begin_loc) = ls_current_loc(s);
	}
	tbl ::= (internal->tbl);
	return (tbl->tbl) at char;
};

lex_discard ::= func(s : lex_state mut&) -> v0
{
	(s->internal) = zero;
};

lex_next ::= func(s : lex_state mut&) -> v0
{
	entry ::= lex_get(s);
	should_advance : bool mut;
	should_advance = true;
	internal ::= ref(s->internal);

	(internal->tbl) = ((entry->next)@lex_table&);
	if((entry->tag) == zero)
	{
		// invalid operation
		psyc_error_begin(internal->begin_loc);
		puts("failed to lex ");
		putchar('"');
		ptr ::= (s->src) at (internal->begin_cursor);
		cur ::= (s->cursor) + 1;
		putss(ptr, cur - (internal->begin_cursor));
		putchar('"');
		psyc_diag_end();
		psyc_exit_failure();
		return;
	}
	if((entry->tag) == (lex_entry_tag.none))
	{
		// valid operation, but we dont do anything.
	}
	if((entry->tag) == (lex_entry_tag.success))
	{
		if((entry->metadata)@bool)
		{
			should_advance = false;
		}
		ls_push_token(s, token_data
		{
			.tok := (entry->data)@lex_token;
			.lexeme := lex_slice{.off := (internal->begin_cursor); .len := (s->cursor) - (internal->begin_cursor);};
			.begin := (internal->begin_loc);
			.end := ls_current_loc(s);
		});	
		puts("found token ");
		puts(__enumname((entry->data)@lex_token));
		putchar(10);
		lex_discard(s);
	}
	if((entry->tag) == (lex_entry_tag.discard))
	{
		lex_discard(s);
	}

	if(should_advance)
	{
		lex_advance(s);
	}
};

lex ::= func(path : u8&, src : u8&, verbose_lex : bool) -> lex_state
{
	psyc_timed(psyc_stage.lex);
	ret : lex_state mut := zero;
	(ret.line) = 1;
	(ret.col) = 1;
	(ret.path) = path;
	(ret.src) = src;
	(ret.tokens_cap) = 1024;
	(ret.tokens) = arena_push(lexar, __sizeof(deref (ret.tokens)) * (ret.tokens_cap));
	len ::= cstrlen(src);

	while((ret.cursor) < len@_)
	{
		lex_next(ref ret);
	}

	if(verbose_lex)
	{
		ls_verbose_print(ref ret);
	}
	return ret;
};

== build ==
{
	add_source_file("diag.psy");
}
