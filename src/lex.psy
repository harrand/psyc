lexar : arena mut& mut;

impl_is_punctuation ::= func(ch : u8) -> bool
{
	if(ch >= 'a')
	{
		if(ch <= 'z')
		{
			return false;
		}
	}
	if(ch >= 'A')
	{
		if(ch <= 'Z')
		{
			return false;
		}
	}
	if(ch >= '0')
	{
		if(ch <= '9')
		{
			return false;
		}
	}
	return true;
};

lex_token ::= enum
{
	.comment := 0;
	.multicomment := 1;
	.numeric_literal := 2;
	.char_literal := 3;
	.string_literal := 4;
	.semicol := 5;
	.initialiser := 6;
	.colon := 7;
	.comma := 8;
	.dot := 9;
	.compare := 10;
	.comparen := 11;
	.assign := 12;
	.arrow := 13;
	.oparen := 14;
	.cparen := 15;
	.obrace := 16;
	.cbrace := 17;
	.obrack := 18;
	.cbrack := 19;
	.plus := 20;
	.dash := 21;
	.asterisk := 22;
	.fslash := 23;
	.cast := 24;
	.arr := 25;
	.logical_and := 26;
	.bitwise_and := 27;
	.logical_or := 28;
	.bitwise_or := 29;
	.bitwise_exor := 30;
	.modulo := 31;
	.bitwise_invert := 32;
	.logical_invert := 33;
	.loreq := 34;
	.goreq := 35;
	.oanglebrack2 := 36;
	.canglebrack2 := 37;
	.oanglebrack := 38;
	.canglebrack := 39;
	.keyword_static_if := 40;
	.keyword_if := 41;
	.keyword_else := 42;
	.keyword_while := 43;
	.keyword_for := 44;
	.keyword_return := 45;
	.keyword_yield := 46;
	.keyword_func := 47;
	.keyword_macro := 48;
	.keyword_extern := 49;
	.keyword_struct := 50;
	.keyword_enum := 51;
	.keyword_ref := 52;
	.keyword_deref := 53;
	.keyword_atomic_deref := 54;
	.keyword_defer := 55;
	.keyword_alias := 56;
	.keyword_at := 57;
	.keyword_true := 58;
	.keyword_false := 59;
	.keyword_zero := 60;
	.symbol := 61;
};

lex_slice ::= struct
{
	off : u64;
	len : u64;
};

token_data ::= struct
{
	tok : lex_token;
	lexeme : lex_slice;
	begin : srcloc;
	end : srcloc;
};

lex_entry_tag ::= enum
{
	// data is a pointer to a function
	.fn := 1;
	// data is a pointer to the next lex_trivial_table
	.tbl := 2;
	// data is the token type you have just found.
	.success := 3;
};

lex_entry ::= struct
{
	tag : lex_entry_tag;
	data : u64;
	metadata : u64 weak;
};

lex_trivial_table ::= struct
{
	tbl : lex_entry mut&;
	cap : u64;
};

tables : lex_trivial_table mut#8;

lex_internal_state ::= struct
{
	begin_cursor : u64;
	begin : srcloc;
	started : bool;
	curlen : u64;
	ent : lex_entry mut;
};

lex_state ::= struct
{
	path : u8&;
	src : u8&;
	cursor : u64;
	line : u64;
	col : u64;

	tokens : token_data mut&;
	tokens_size : u64;
	tokens_cap : u64;

	internal : lex_internal_state;
};

td_print ::= func(s : lex_state&, tok : token_data) -> v0
{
	slice ::= tok.lexeme;
	puts(__enumname(tok.tok));
	putchar(' ');
	lexeme_data ::= (s->src) at (slice.off);
	j : u64 mut;
	for(j = 0, j < (slice.len), j = j + 1)
	{
		putchar(deref(lexeme_data at j));
	}
	putchar(' ');
	print_srcloc(tok.begin);
	putchar(10);
};

ls_current_loc ::= func(s : lex_state&) -> srcloc
{
	return srcloc
	{
		.file := (s->path);
		.function := "";
		.line := (s->line);
		.column := (s->col);
	};
};


ls_newtable ::= func() -> lex_trivial_table
{
	cap ::= 255;
	ptr ::= arena_push(lexar, cap * __sizeof(lex_entry));
	__memset(ptr, 0, cap * __sizeof(lex_entry));
	return lex_trivial_table
	{
		.tbl := ptr;
		.cap := cap;
	};
};

ls_table_set_table ::= func(tbl : lex_trivial_table mut&, idx : u64, valtbl : lex_trivial_table&) -> v0
{
	ptr ::= (tbl->tbl) at idx;
	(deref ptr) = lex_entry
	{
		.tag := lex_entry_tag.tbl;
		.data := valtbl@u64;
	};
};

ls_table_set_fn ::= func(tbl : lex_trivial_table mut&, idx : u64, valfn : func(s : lex_state mut&) -> v0) -> v0
{
	ptr ::= (tbl->tbl) at idx;
	(deref ptr) = lex_entry
	{
		.tag := lex_entry_tag.fn;
		.data := valfn@u64;
	};
};

testfn ::= func(s : lex_state mut&) -> v0
{
	psyc_panic(ls_current_loc(s), "testfn hit!");
};

trivial_setup ::= func(t : lex_token, front_identifier : u8&, require_proceeding_whitespace : bool) -> v0
{
	len : u64 mut := cstrlen(front_identifier);
	if(!require_proceeding_whitespace)
	{
		len = len - 1;
	}
	tbl : lex_trivial_table& mut := tables at 0;
	i : u64 mut := 0;
	for(i = 0, i < len, i = i + 1)
	{
		ch ::= deref(front_identifier at i);
		entryptr ::= (tbl->tbl) at ch;
		if((entryptr->tag) == (lex_entry_tag.tbl))
		{
			// sick just re-use it
			tbl = ((entryptr->data)@lex_trivial_table&);
		}
		if((entryptr->tag) == (lex_entry_tag.fn))
		{
			psyc_panic(zero, "waahfn");
		}
		if((entryptr->tag) == (lex_entry_tag.success))
		{
			psyc_panic(zero, "waahsucc");
		}
		if((entryptr->tag) == zero)
		{
			// make a new table.
			newtblptr : lex_trivial_table mut& := arena_push(lexar, __sizeof(lex_trivial_table));
			deref(newtblptr) = ls_newtable();
			(deref entryptr) = lex_entry
			{
				.tag := lex_entry_tag.tbl;
				.data := newtblptr@u64;
			};
			tbl = newtblptr;
		}
	}

	if(!require_proceeding_whitespace)
	{
		last ::= deref(front_identifier at len);
		deref((tbl->tbl) at last) = lex_entry
		{
			.tag := lex_entry_tag.success;
			.data := t@s64@u64;
			.metadata := true;
		};
	}
	if(require_proceeding_whitespace)
	{
		for(i = 0, i < 255, i = i + 1)
		{
			char ::= i@u8;
			if(impl_is_punctuation(char))
			{
				deref((tbl->tbl) at i) = lex_entry
				{
					.tag := lex_entry_tag.success;
					.data := t@s64@u64;
					.metadata := false;
				};
			}
		}
	}
};

lex_setup ::= func(a : arena mut&) -> v0
{
	psyc_timed(psyc_stage.setup);
	lexar = a;

	deref(tables at 0) = ls_newtable();
	//ls_table_set_fn(tables at 0, '_', testfn);
	trivial_setup(lex_token.semicol, ";", false);
	trivial_setup(lex_token.keyword_true, "true", true);
};

ls_verbose_print ::= func(s : lex_state&) -> v0
{
	puts(s->path);
	putchar(':');
	putchar(10);
	putchar('{');
	putchar(10);
	// just print out all token datas.
	i : u64 mut;
	for(i = 0, i < (s->tokens_size), i = i + 1)
	{
		tok ::= deref ((s->tokens) at i);
		td_print(s, tok);
	}
	putchar('}');
	putchar(10);
};

ls_push_token ::= func(state : lex_state mut&, token : token_data) -> v0
{
	if((state->tokens) == null)
	{
		psyc_panic(srcloc_current(), "lex_state did not initialise its token list correctly. it was null.");
	}
	if((state->tokens_size) >= (state->tokens_cap))
	{
		oldcap ::= state->tokens_cap;
		old_tokens ::= state->tokens;

		(state->tokens_cap) = (state->tokens_cap) * 2;
		(state->tokens) = arena_push(lexar, __sizeof(deref (state->tokens)) * (state->tokens_cap));
		__memcpy(state->tokens, old_tokens, __sizeof(deref (state->tokens)) * oldcap);
	}
	deref((state->tokens) at (state->tokens_size)) = token;
	(state->tokens_size) = (state->tokens_size) + 1;
};

token_affects_code ::= func(tok : lex_token) -> bool
{
	return true;
};

impl_is_whitespace ::= func(char : u8) -> bool
{
	if(char == 0x20) // ' '
	{
		return true;
	}
	if(char == 0x0c) // '\f'
	{
		return true;
	}
	if(char == 0x0a) // '\n'
	{
		return true;
	}
	if(char == 0x0d) // '\r'
	{
		return true;
	}
	if(char == 0x09) // '/t'
	{
		return true;
	}
	if(char == 0x0b) // '/v'
	{
		return true;
	}
	return false;
};

impl_is_alpha ::= func(char : u8) -> bool
{
	if(char >= 'a')
	{
		if(char <= 'z')
		{
			return true;
		}
	}
	if(char >= 'A')
	{
		if(char <= 'Z')
		{
			return true;
		}
	}
	return false;
};

lex_onwards ::= func(s : lex_state mut&) -> bool
{
	while(impl_is_whitespace(deref((s->src) at (s->cursor))))
	{
		is_newline ::= deref((s->src) at (s->cursor)) == 10;
		if(is_newline)
		{
			(s->line) = (s->line) + 1;
			(s->col) = 1;
		}
		if(!is_newline)
		{
			(s->col) = (s->col) + 1;
		}
		(s->cursor) = (s->cursor) + 1;
	}
	return (s->cursor) < cstrlen(s->src);
};

lex_advance ::= func(s : lex_state mut&) -> v0
{
	whitespace ::= impl_is_whitespace(deref((s->src) at (s->cursor)));
	if(whitespace)
	{
		(s->line) = (s->line) + 1;
		(s->col) = 1;
	}
	if(!whitespace)
	{
		(s->col) = (s->col) + 1;
	}
	(s->cursor) = (s->cursor) + 1;
};

lex_get ::= func(tbl : lex_trivial_table& mut, s : lex_state mut&) -> lex_entry
{
	char ::= deref((s->src) at (s->cursor))@u64;
	if(tbl == null)
	{
		// probably the first time. just get the first table.
		tbl = (tables at 0);
	}
	// so how do we index into the table?
	// just index into it for now
	if(char >= (tbl->cap))
	{
		psyc_panic(ls_current_loc(s), "lex table index is out of range");
	}
	return deref ((tbl->tbl) at char);
};

lex_next ::= func(s : lex_state mut&) -> v0
{
	int ::= ref(s->internal);
	if(!lex_onwards(s))
	{
		return;
	}
	started ::= int->started;
	if(started)
	{
		oldent ::= int->ent;
		tbl ::= (oldent.data)@lex_trivial_table&;
		(int->ent) = lex_get(tbl, s);
		(int->curlen) = (int->curlen) + 1;
	}
	if(!started)
	{
		(int->started) = true;
		(int->ent) = lex_get(null, s);
		(int->begin_cursor) = (s->cursor);
		(int->begin) = ls_current_loc(s);
	}

	// check int->ent
	// if its success, then pop a token out
	// else, continue;
	ent ::= (int->ent);
	if((ent.tag) == (lex_entry_tag.success))
	{
		// hooray! new token.
		if((ent.metadata)@bool)
		{
			lex_advance(s);
		}
		ls_push_token(s, token_data
		{
			.tok := (ent.data)@lex_token;
			.lexeme := lex_slice{.off := (int->begin_cursor); .len := (s->cursor) - (int->begin_cursor);};
			.begin := int->begin;
			.end := ls_current_loc(s);
		});
		// reset the internal state
		(deref int) = zero;
		return;
	}
	if((ent.tag) == (lex_entry_tag.tbl))
	{
		tbl ::= (ent.data)@lex_trivial_table&;
		lex_advance(s);
		return;
	}
	if((ent.tag) == (lex_entry_tag.fn))
	{
		fn : func(s : lex_state mut&) -> v0 := (ent.data)@_;
		fn(s);
		lex_advance(s);
		return;
	}
	//if((ent.tag) == zero)
	//{
		// this didnt give us anything useful.
		// todo: proper tokenise_fn like the old ways? for comments/symbols etc
	//}
	ls_verbose_print(s);
	psyc_panic_begin(ls_current_loc(s));
	puts("got lex entry tag: ");
	puts(__enumname(ent.tag));
	puts(" (");
	putsint((ent.tag)@s64);
	puts(")");
	psyc_diag_end();
	psyc_exit_failure();
};

lex ::= func(path : u8&, src : u8&, verbose_lex : bool) -> lex_state
{
	psyc_timed(psyc_stage.lex);
	ret : lex_state mut := zero;
	(ret.line) = 1;
	(ret.col) = 1;
	(ret.path) = path;
	(ret.src) = src;
	(ret.tokens_cap) = 1024;
	(ret.tokens) = arena_push(lexar, __sizeof(deref (ret.tokens)) * (ret.tokens_cap));
	len ::= cstrlen(src);

	while((ret.cursor) < len@_)
	{
		lex_next(ref ret);
	}

	if(verbose_lex)
	{
		ls_verbose_print(ref ret);
	}
	return ret;
};

== build ==
{
	add_source_file("diag.psy");
}
