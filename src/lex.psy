lexar : arena mut& mut;

lex_token ::= enum
{
	.comment := 0;
	.multicomment := 1;
	.numeric_literal := 2;
	.char_literal := 3;
	.string_literal := 4;
	.semicol := 5;
	.initialiser := 6;
	.colon := 7;
	.comma := 8;
	.dot := 9;
	.compare := 10;
	.comparen := 11;
	.assign := 12;
	.arrow := 13;
	.oparen := 14;
	.cparen := 15;
	.obrace := 16;
	.cbrace := 17;
	.obrack := 18;
	.cbrack := 19;
	.plus := 20;
	.dash := 21;
	.asterisk := 22;
	.fslash := 23;
	.cast := 24;
	.arr := 25;
	.logical_and := 26;
	.bitwise_and := 27;
	.logical_or := 28;
	.bitwise_or := 29;
	.bitwise_exor := 30;
	.modulo := 31;
	.bitwise_invert := 32;
	.logical_invert := 33;
	.loreq := 34;
	.goreq := 35;
	.oanglebrack2 := 36;
	.canglebrack2 := 37;
	.oanglebrack := 38;
	.canglebrack := 39;
	.keyword_static_if := 40;
	.keyword_if := 41;
	.keyword_else := 42;
	.keyword_while := 43;
	.keyword_for := 44;
	.keyword_return := 45;
	.keyword_yield := 46;
	.keyword_func := 47;
	.keyword_macro := 48;
	.keyword_extern := 49;
	.keyword_struct := 50;
	.keyword_enum := 51;
	.keyword_ref := 52;
	.keyword_deref := 53;
	.keyword_atomic_deref := 54;
	.keyword_defer := 55;
	.keyword_alias := 56;
	.keyword_at := 57;
	.keyword_true := 58;
	.keyword_false := 59;
	.keyword_zero := 60;
	.symbol := 61;
};

lex_slice ::= struct
{
	off : u64;
	len : u64;
};

token_data ::= struct
{
	tok : lex_token;
	lexeme : lex_slice;
	begin : srcloc;
	end : srcloc;
};

lex_entry_tag ::= enum
{
	// data is a pointer to a function
	.fn := 1;
	// data is a pointer to the next lex_trivial_table
	.tbl := 2;
	// data is the token type you have just found.
	.success := 3;
};

lex_entry ::= struct
{
	tag : lex_entry_tag;
	data : u64;
};

lex_trivial_table ::= struct
{
	tbl : lex_entry mut&;
	len : u64;
	cap : u64;
};

tables : lex_trivial_table mut#8;

lex_internal_state ::= struct
{
	curlen : u64;
};

lex_state ::= struct
{
	path : u8&;
	src : u8&;
	cursor : u64;
	line : u64;
	col : u64;

	tokens : token_data mut&;
	tokens_size : u64;
	tokens_cap : u64;

	internal : lex_internal_state;
};

td_print ::= func(s : lex_state&, tok : token_data) -> v0
{
	slice ::= tok.lexeme;
	puts(__enumname(tok.tok));
	putchar(' ');
	lexeme_data ::= (s->src) at (slice.off);
	j : u64 mut;
	for(j = 0, j < (slice.len), j = j + 1)
	{
		putchar(deref(lexeme_data at j));
	}
	putchar(' ');
	print_srcloc(tok.begin);
	putchar(10);
};

lex_setup ::= func(a : arena mut&) -> v0
{
	psyc_timed(psyc_stage.setup);
	lexar = a;

	deref(tables at 0) = lex_trivial_table
	{
	};
};

ls_verbose_print ::= func(s : lex_state&) -> v0
{
	puts(s->path);
	putchar(':');
	putchar(10);
	putchar('{');
	putchar(10);
	// just print out all token datas.
	i : u64 mut;
	for(i = 0, i < (s->tokens_size), i = i + 1)
	{
		tok ::= deref ((s->tokens) at i);
		td_print(s, tok);
	}
	putchar('}');
	putchar(10);
};

token_affects_code ::= func(tok : lex_token) -> bool
{
	return true;
};

lex ::= func(path : u8&, src : u8&, verbose_lex : bool) -> lex_state
{
	psyc_timed(psyc_stage.lex);
	ret : lex_state mut := zero;
	(ret.line) = 1;
	(ret.col) = 1;
	(ret.path) = path;
	(ret.src) = src;
	(ret.tokens_cap) = 1024;
	(ret.tokens) = arena_push(lexar, __sizeof(deref (ret.tokens)) * (ret.tokens_cap));
	len ::= cstrlen(src);

	if(verbose_lex)
	{
		ls_verbose_print(ref ret);
	}
	return ret;
};

== build ==
{
	add_source_file("diag.psy");
}
